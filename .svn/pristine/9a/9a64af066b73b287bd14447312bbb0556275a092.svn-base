Kevin C. Chang
Query Optimization
Database Systems
 
 
• Query optimization, query optimizer
• Logical query plans
• Algebraic laws of equivalence
• Rule-based optimization, Heuristic
• Cost-based optimization
• Join trees
• Dynamic programming
• Physical query plans
• Intermediate results, pipeline, materialization
• Estimating sizes
Concepts You Will Learn
Query Optimization (1 of 64)Default Section (1 of 2)
 
This is the concept road map 
The Big Picture: Where We Are
Query Optimization (2 of 64)
Data Access
Data Modeling
Data/Query Processing
Data Acquisition
Relational NonRelational
St
ru
ct
u
re
d
Se
m
iS
tr
u
ct
u
re
d
Transaction Management
N
o
SQ
L 
D
at
a
b
a
se
s
X
M
L 
D
at
a
b
a
se
s
U
n
tr
u
ct
u
re
d
Relational Databases
• SQL
• Relational Algebra
• Query Optimization
• Query Execution
• Indexing
• Concurrency Control
• Logging Recovery
Database Systems Toolkits
M
a
p
 R
e
d
u
ce
(P
a
ra
lle
l)
St
o
rm
 
(S
tr
e
a
m
)
Information Extraction
ER  Relational Model
Query Language
Default Section (2 of 2)
 
Reviews from previous few lectures: 
 Indexing: Given value or keyword, 
how to find them on disk. 
 Query Execution: Concept of 
cost, requirements of memory. 
 One-pass Algorithm: Process 
relation once (more memory 
required). 
 Two-pass Algorithm: 1.Organize 
data by hash/sorted list 2. Process 
query. 
 Zero-pass: using index. 
From now: 
 Query optimizer: Generate 
strategic plan when got the 
query. The quality of the plan 
determines the efficiency of 
query execution. 
Why Do We Learn This?
Query Optimization (3 of 64)Why Do We Learn This? (0 of 0)
 
The performance is very important 
Three most important factors in DB: 
1. Performance 
2. Reliability  
3. High level declarative 
 TPC: Use database plus  hardware to test 
the speed of database. 
Overview
Query Optimization (4 of 64)Overview (0 of 5)
 
 
• At the heart of the database engine
• Step 1: convert the SQL query to some logical plan
• Step 2: find a better logical plan, find an associated 
physical plan
Optimization
Query Optimization (5 of 64)Overview (1 of 5)
 
 Logical plan: Relational algebra 
level, different operations are 
only defined by their input and 
output, e.g. join, selection, etc. 
 Physical plan: Implementation 
level, e.g. hash-based join, index-
based join. 
 We now focus on Physical Plan 
SELECT a1, …, an
FROM R1, …, Rk
WHERE C
 
       
                   
Converting from SQL to Logical Plans
Query Optimization (6 of 64)Overview (2 of 5)
 
The lower part of the slide is already a 
query plan, but it is not efficiency because 
Cartesian product combines everything 
with anything which is often not 
necessary. 
• Now we have one logical plan
• Algebraic laws:
• foundation for every optimization
• Two approaches to optimizations:
• Rule-based (heuristics): apply laws that seem to result in 
cheaper plans
• Cost-based: estimate size and cost of intermediate 
results, search systematically for best plan
Optimization: Logical Query Plan
Query Optimization (7 of 64)Overview (3 of 5)
 
1. Algebraic laws gives the equivalence 
plan.  
Rule-Base Optimizer (RBO): See more 
from Oracle’s documentation 
http://docs.oracle.com/cd/B10500_01/se
rver.920/a96533/rbo.htm 
2. Cost based are design according to 
better run times. The cost to run the 
same query may be different from time to  
time. 
Cost-Based Optimizer (CBO): No fixed 
rule, while believe in run-time cost. See 
more http://www.oracle-
base.com/articles/misc/cost-based-
optimizer-and-database-statistics.php 
3. Heuristics refers to experience-based 
techniques for problem solving, learning, 
and discovery that give a solution which is 
not guaranteed to be optimal. 
Select S.name, C.instructor
From Students S, Enrollment E, Course C
Where S.dept = ‘CS’ and 
S.sid=E.sid and E.cid = C.cid
Motivating Example
Query Optimization (8 of 64)Overview (4 of 5)
 
Suppose we have 40k students, 1k 
classes, 200k enrollment. 
 
1. We first join Students and Enrollment, 
and then Courses.  
2. For second diagram. Because we only 
care about students in CS, we can first 
select the cs students from Students then 
join with Enrollment. The query can be 
optimized. 
3. For example on the third diagram, If we 
have less students in Summer, we will 
have less enrollment which would be 
optimized to join Enrollment and Classes 
first then with the Cs students. 
All of the above plans will give the correct 
result because of the algebraic laws that 
we will learn it in few slides. 
• We need three things in an optimizer:
• Algebraic laws
• A cost estimator
• An optimization algorithm
The three components of an optimizer
Query Optimization (9 of 64)Overview (5 of 5)
 
1. Algebraic laws tell us the possible 
plans. 
2. A cost estimator tells us the cost of 
each plan. 
3. Optimization algorithm can help us find 
the most efficient plan(P*). 
Algebraic Laws
Query Optimization (10 of 64)Algebraic Laws (0 of 4)
 
 
• Commutative and Associative Laws
•                            
•                                        
•                                        
• Distributive Laws
•                              
Algebraic Laws
Query Optimization (11 of 64)
Q: How to prove these laws?
Algebraic Laws (1 of 4)
 
If we want to prove these laws we need 
to show tuples belongs to LHS if and only 
if tuples belongs to RHS. 
• Laws involving selection:
•                                       
•                     
•                    
• When C involves only attributes of R
•                 
•             
•                
• Q: What do they mean? Make sense?
Algebraic Laws
Query Optimization (12 of 64)Algebraic Laws (2 of 4)
 
With these laws we can push selection 
down. By push down and up we mean 
query trees. 
We can push down a selection up in the 
tree to bottom to narrow down the 
results.  
Push selection down is a heuristic rule 
which have a high chance to be true but 
not guarantee to be true. Showing the 
fragility of RBO (rule-based optimizer). 
 
• Example:                     
•                                                          
•                                                  
Algebraic Laws
Query Optimization (13 of 64)Algebraic Laws (3 of 4)
 
(a) Because S have attribute F,  we push 
selection to S which becomes R natural 
join selection of S. 
(b) Same for b. Because A belong to R and 
G belongs to A, selection of A=5 push to R 
and selection of G=9 push to S. 
• Laws involving projections
•                             
• Where N, P, Q are appropriate subsets of attributes of M
•                      
• Example                    
•                                 
Algebraic Laws
Query Optimization (14 of 64)Algebraic Laws (4 of 4)
 
The first ? should be ABG because we 
need them. 
The second ? should be AB because we 
need them and D because we need it to 
join. 
Same for third ?. It should be E and G. G 
for projection and E for join. 
Optimizer
Query Optimization (15 of 64)Optimizer (0 of 2)
 
 
Behind the Scene: Oracle RBO and CBO
Query Optimization (16 of 64)
• Oracle 7 (1992) prior (since 1979): RBO.
• Oracle 7-10: RBO + CBO.
• Oracle 10g (2003): CBO.
Optimizer (1 of 2)
 
 
Behind the Scene: Oracle RBO and CBO
Query Optimization (17 of 64)Optimizer (2 of 2)
 
 
Rule-based Optimization
Query Optimization (18 of 64)Rule-based Optimization (0 of 3)
 
 
• Query rewriting based on heuristic/algebraic laws
• Result in better queries most of the time
• Heuristics number 1:
• Push selections down
• Heuristics number 2:
• Sometimes push selections up, then down
Ruler-ased Optimizations
Query Optimization (19 of 64)Rule-based Optimization (1 of 3)
 
Push selection down and up are all rules. 
Predicate Pushdown
Product Company
                            
      
            
Product(pname, maker, price) Company(cname, city)
Rule-based Optimization (2 of 3) Query Optimization (20 of 64)
 
We can push price > 100 down to product 
and city=”Urbana” down to Company. 
But this is not always make sense, if 
companies in Urbana do not have 
products higher than 100. 
This is when we need cost-based 
optimization. 
Cost-based Optimization
Query Optimization (22 of 64)Cost-based Optimization (0 of 5)
 
 
Behind the Scene: The Selinger Style!
Query Optimization (23 of 64)Cost-based Optimization (1 of 5)
 
 
Behind the Scene: The Selinger Style!
Query Optimization (24 of 64)Cost-based Optimization (2 of 5)
 
 
• Main idea: apply algebraic laws, until estimated 
cost is minimal
• Practically: start from partial plans, introduce 
operators one by one
• Will see in a few slides
• Problem: there are too many ways to apply the 
laws, hence too many (partial) plans
Cost-based Optimization
Query Optimization (25 of 64)Cost-based Optimization (3 of 5)
 
 Apply algebraic laws until the 
estimated cost is minimal. Use 
optimization algorithm to guide 
this application of laws, look at 
different plans exhaustively and 
find out the most optimal one. 
 It now becomes a standard search 
problem. 
• Approaches:
• Top-down: the partial plan is a top fragment of the 
logical plan
• Bottom up: the partial plan is a bottom fragment of 
the logical plan
Cost-based Optimization
Query Optimization (26 of 64)Cost-based Optimization (4 of 5)
 
Top down means to build the trees from 
the root.  
Bottom up means to build the trees from 
the leaves. 
 
• Branch-and-bound:
• Remember the cheapest complete plan P seen so far and 
its cost C
• Stop generating partial plans whose cost is > C
• If a cheaper complete plan is found, replace P, C
• Hill climbing:
• Remember only the cheapest partial plan seen so far
• Dynamic programming:
• Remember the all cheapest partial plans
Search Strategies
Query Optimization (27 of 64)Cost-based Optimization (5 of 5)
 
 Branch-and-bound algorithm: 
http://en.wikipedia.org/wiki/Bran
ch_and_bound 
 Hill climbing: 
http://en.wikipedia.org/wiki/Hill_
climbing 
 Dynamic programming:  
http://en.wikipedia.org/wiki/Dyn
amic_programming 
Dynamic Programming
Query Optimization (28 of 64)Dynamic Programming (0 of 12)
 
 
•                 
• Join tree:
• A plan = a join tree
• A partial plan = a subtree of a join tree
Join Trees
Query Optimization (29 of 64)
R3 R1 R2 R4
Dynamic Programming (1 of 12)
 
Because the database is so large not all 
the situations can be considered, we need 
to make some assumptions.   
In the example on left, we make an 
assumption that it only have binary join. 
This simplifies the space of 
implementation. 
• Left deep:
Types of Join Trees
Query Optimization (30 of 64)
R3 R1
R5
R2
R4
Dynamic Programming (2 of 12)
 
1. Left deep tree enable pipeline easy. 
Because every operators only depend one 
preceding operator, previous operator 
finished something , the operator have 
some tuples to process. Then we can have 
a whole line to process. 
2. Memory requirement is smaller.  We 
only process one relation and add other 
relation to it which means there is only 
one working space. 
• Bushy:
Types of Join Trees
Query Optimization (31 of 64)
R3
R1
R2 R4
R5
Dynamic Programming (3 of 12)
 
1. Difficult to pipeline. In the case on the 
left, we have to make both line below 
root to work to make it pipeline. 
2. Need more memory. It need to two 
working spaces to make both operators 
working. 
 
Try to avoid this structure. 
• Right deep:
Types of Join Trees
Query Optimization (32 of 64)
R3
R1
R5
R2 R4
Dynamic Programming (4 of 12)
 
 Symmetric to left deep. 
 Same concept. 
FYI 
Left-deep tree: 
http://protogenist.wordpress.com/ta
g/left-deep-trees/ 
Left deep vs. bushy: 
http://jonathanlewis.wordpress.com/
2007/01/24/left-deep-trees/ 
• Given: a query                  
• Assume we have a function cost() that gives us the 
cost of every join tree
• Find the best join tree for the query
Problem
Query Optimization (33 of 64)Dynamic Programming (5 of 12)
 
Goal:  
1. find the possible plans;  
2. find the optimal plan. (need a search 
algorithm) 
3. estimate the cost to measure the 
quality of the plans 
• Idea: for each subset of          compute the 
best plan for that subset
• In increasing order of set cardinality:
•                             
•                                        
•  
•                      
• For each subset of        , also called a subquery, 
compute the following:
• Size(Q)
• Best plan for Q: Plan(Q)
• Cost of that plan: Cost(Q)
Dynamic Programming
Query Optimization (34 of 64)Dynamic Programming (6 of 12)
 
Here is an assumption behind the 
algorithm: The optimization of the small 
set is also a subset of the optimization of 
the bigger tree. i.e.: {small set}* = the 
best for the big tree.  
Dynamic Programming breaks down the 
problem and makes an incremental step-
by-step optimization. (The current step is 
based on previous optimal result. ) 
• To illustrate, we will make the following 
simplifications:
•                                       
                             
• Intermediate results:
• If P1 = a join, then the size of the intermediate result is 
size(P1), otherwise the size is 0
• Similarly for P2
• Cost of a scan = 0, i.e.,         = 0.
Dynamic Programming
Query Optimization (35 of 64)Dynamic Programming (7 of 12)
 
Example:  
Suppose P1 is a join between R1 and R2 
and P2 is a single relation of R3. Then,  
Cost(P1 ⋈ P2) = Cost(P1) + Cost(P2) + 
size(P1) 
• Example:
•                                    
                             = 0
•                
                                     
     
               
Dynamic Programming
Query Optimization (36 of 64)Dynamic Programming (8 of 12)
 
Two examples (formulas) need to be 
supplemented.  
1. Cost((R1 ⋈ R2) ⋈ (R3 ⋈ R4))  
= Cost(R1 ⋈ R2) + Cost(R3 ⋈ R4) + Size 
(R1 ⋈ R2) + Size (R3 ⋈ R4) 
= Size (R1 ⋈ R2) + Size (R3 ⋈ R4)  
(According to the example of Cost(R1 ⋈ 
R2)=0) 
2. Cost((R1 ⋈ R2 ⋈ R3) ⋈ R4) 
=Cost(R1 ⋈ R2 ⋈ R3) + Cost(R4) + 
Size(R1 ⋈ R2 ⋈ R3) 
= Cost(R1 ⋈ R2 ⋈ R3) + Size(R1 ⋈ R2 ⋈ 
R3) 
(Cost(R4)=0) 
• Relations:        
• Number of tuples: 2000, 5000, 3000, 1000
• Size estimation:                          
Dynamic Programming
Query Optimization (37 of 64)Dynamic Programming (9 of 12)
 
The number of tuples is defined as T(X).  
For example, T(R) = 2000, T(S) = 5000, T(T) 
=3000, T(U) = 1000 
Example:  
T(R ⋈ S) = 0.01 * T(R) * T(S)  
=0.01*2000*5000  
= 100k 
Query Optimization (38 of 64)
Subquery Size Cost Plan
RS
RT
RU
ST
SU
TU
RST
RSU
RTU
STU
RSTU
Dynamic Programming (10 of 12)
 
This is the sheet for dynamic 
programming.  
Steps:  
1. calculate the 1-relation subqueries (R, 
S, T, U);  
2. calculate the 2-relation subqueries (RS, 
RT…);  
3. calculate the 3-relation subqueries 
(RST, RTU…); 
4. calculate the 4-relation subqueries 
(RSTU); 
 
We will fill it up in the next slide.  
Query Optimization (39 of 64)
Subquery Size Cost Plan
RS 100k 0 RS
RT 60k 0 RT
RU 20k 0 RU
ST 150k 0 ST
SU 50k 0 SU
TU 30k 0 TU
RST 3M 60k (RT)S
RSU 1M 20k (RU)S
RTU 0.6M 20k (RU)T
STU 1.5M 30k (TU)S
RSTU 30M 60k+50k=110k (RT)(SU)
Dynamic Programming (11 of 12)
 
1. For the subquery of RS:  
According to the formula of Cost(R1 ⋈ 
R2) = 0, Cost(RS) = 0;  
Size(RS) = T(R) * T(S) = 2000 * 5000 = 100k  
2. The result of the subqueries of RT, RU, 
ST, SU, TU is similar with that of RS.  
3. For the subquery of RST:  
There are three possible plans: (RS)T, 
(RT)S, (ST)R.  
According to the formula of Cost((R1 ⋈ 
R2) ⋈ R3) = size(R1 ⋈ R2), Cost((RS)T) = 
size(RS) = 100k.  
Similarly, Cost((RT)S) = size(RT) = 60k; 
Cost((ST)R) = size(ST) = 150k.  
For smaller cost, we choose the plan of 
(RT)S. According to the formula of T(A ⋈ 
B) = 0.01 * T(A) * T(B), the corresponding 
size is size((RT)S) = size(RT) * size(S) = 0.01 
* 60k * 5000 = 3M.  
4. The result of the subqueries of RSU, 
RTU and STU is similar with that of RST. 
5. For the subquery of RSTU:  
 There are seven possible plans: (RST)U, 
(RSU)T, (RUT)S, (STU)R, (RS)(TU), (RT)(SU), 
(RU)(ST).  
According to the formula of Cost((R1 ⋈ 
R2 ⋈ R3) ⋈ R4) = Cost(R1 ⋈ R2 ⋈ R3) + 
Size(R1 ⋈ R2 ⋈ R3), Cost((RST)U) = 
Cost(RST) + Size(RST) = 3M + 60k.  
Similarly, Cost((RSU)T ) =1M + 20k;  
Cost((RUT)S) = 0.6M + 20k;  
Cost((STU)R) = 1.5M + 30k.  
According to the formula of Cost((R1 ⋈ 
R2) ⋈ (R3 ⋈ R4)) = Size (R1 ⋈ R2) + Size 
(R3 ⋈ R4), Cost((RS)(TU)) = Size(RS) + 
Size(TU) = 100k + 30k  = 130k.  
Similarly, Cost((RT)(SU)) = 110k;  
Cost((RU)(ST)) = 170k.  
For smaller cost, we choose the plan of 
(RT)(SU). According to the formula of T(A 
⋈ B) = 0.01 * T(A) * T(B), the 
corresponding size is size((RT)(SU)) = 
size(RT) * size(SU) = 0.01 * 60k * 50k = 
30M.  
However, if the final plan should be a left 
deep tree, the plans of  (RS)(TU), (RT)(SU) 
and (RU)(ST) should not be considered.  
 
• Summary: computes optimal plans for subqueries:
• Step 1: {R1},  {R2}, …, {Rn}
• Step 2:  {R1, R2}, {R1, R3}, …, {Rn-1, Rn}
• …
• Step n: {R1, …, Rn}
• We used naïve size/cost estimations
• In practice:
• more realistic size/cost estimations (next time)
• heuristics for Reducing the Search Space 
• Restrict to left linear trees
• Restrict to trees “without Cartesian product”: 
• R(A,B), S(B,C), T(C,D)
• (R join T) join S has a Cartesian product
Dynamic Programming
Query Optimization (40 of 64)Dynamic Programming (12 of 12)
 
The instructor skipped this slide.  
Completing Physical Query Plan
Query Optimization (41 of 64)Completing Physical Query Plan (0 of 13)
 
 
• Choose algorithm to implement each operator
• Need to account for more than cost:
• How much memory do we have ?
• Are the input operand(s) sorted ?
• Decide for each intermediate result:
• To materialize
• To pipeline
Completing the Physical Query Plan
Query Optimization (42 of 64)Completing Physical Query Plan (1 of 13)
 
 
 
The difference between index-based join 
and sort-merge join  
If memory is small, choose index-based 
join; if memory is large, choose sort-
merge join.   
The cost of index-based join is possibly 
much larger than that of sort-merge join. 
R ⋈ S index-
based join 
sort-merge 
join 
Requireme
nt 
index on 
one relation 
N/A 
Memory 1 block of R, 
1 block of S 
B(R)B(S)<M2 
Cost B(R)+T(R)B(S
)/V(S, a) 
5B(R)+5B(S) 
 Material means the intermediate 
result will be created whole and 
stored on disk. 
 Pipelined means the intermediate 
result will be created only in main 
memory and not necessarily kept 
in their entirety at any one time. 
 
Materialize Intermediate Results Between 
Operators
Query Optimization (43 of 64)
 
 
 T
R S
U
HashTable  S
repeat read(R, x)
y  join(HashTable, x)
write(V1, y)
HashTable  T
repeat read(V1, y)
z  join(HashTable, y)
write(V2, z)
HashTable  U
repeat read(V2, z)
u  join(HashTable, z)
write(Answer, u)
V1
V2
Completing Physical Query Plan (2 of 13)
 
Steps:  
1. Generate Hashtable H(S) with the cost 
of B(S);  
2. Read every tuple of R and join with the 
H(S). Then write into the disk. The total 
cost is B(R ⋈ S).  
3. Generate Hashtable H(T) with the cost 
of B(T); 
4. Read R ⋈ S with the cost of B(R ⋈ S) 
and then join with H(T). Then write into 
the disk with the cost of B(R ⋈ S ⋈ T).  
5. Generate Hashtable H(U) with the cost 
of B(U); 
6. Read R ⋈ S ⋈ T with the cost of B(R ⋈ 
S ⋈ T) and then join with H(U). Then 
output the result.  
The total cost and the memory will be 
shown in the next slide.  
• Given B(R), B(S), B(T), B(U)
• What is the total cost of the plan ?
• Cost = 
• How much main memory do we need ?
• M = 
Materialize Intermediate Results Between 
Operators
Query Optimization (44 of 64)Completing Physical Query Plan (3 of 13)
 
As the steps shown in the previous slide,  
Cost = B(R) + B(S) + B(T) + B(U) + 2*B(R ⋈ 
S) + B(R ⋈ S ⋈ T). 
Memory = Max(B(S), B(T), B(U)).  
(As only one tuple is read each time, B(R) 
should not be included when calculating 
the memory) 
Pipeline Between Operators
Query Optimization (45 of 64)
 
 
 T
R S
U
HashTable1  S
HashTable2  T
HashTable3  U
repeat read(R, x)
y  join(HashTable1, x) 
z  join(HashTable2, y)
u  join(HashTable3, z)
write(Answer, u)
How much main memory do we need ? M =
Completing Physical Query Plan (4 of 13)
 
Steps:  
1. Generate Hashtable H(S) with the cost 
of B(S); 
2. Generate Hashtable H(T) with the cost 
of B(T); 
3. Generate Hashtable H(U) with the cost 
of B(U); 
4. Read every tuple of R and join with 
H(S). Then join with H(T). Then join with 
H(U) Then output the answer.  
 
• Given B(R), B(S), B(T), B(U)
• What is the total cost of the plan ?
• Cost = 
• How much main memory do we need ?
• M = 
Pipeline Between Operators
Query Optimization (46 of 64)Completing Physical Query Plan (5 of 13)
 
As the steps shown in the previous slide,  
Cost = B(R) + B(S) + B(T)+ B(U).  
Memory = B(S) + B(T) + B(U).  
(The instructor wrote B(S) + B(R) + B(T), 
but I think it should be wrong. ) 
Compared with the Materializing method, 
the pipeline method does not need to 
write the result into the disk during the 
procedure and therefore occupies more 
memory.  
• Choose algorithm to implement each operator
• Need to account for more than cost:
• How much memory do we have ?
• Are the input operand(s) sorted ?
• Decide for each intermediate result:
• To materialize
• To pipeline
Completing the Physical Query Plan
Query Optimization (47 of 64)Completing Physical Query Plan (6 of 13)
 
 The instructor skipped this slide. 
• Logical plan is:
• Main memory M = 101 buffers
Example
Query Optimization (48 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (7 of 13)
 
In the 101 buffers, 1 should be hold for 
input buffer.  
If k is very big, we should use 
materializing, because we need to write 
the bucket out; If k is very small, we could 
use pipeline method, because we could 
save the bucket into the memory.  
• Naïve evaluation: 
• 2 partitioned hash-joins
• Cost 3B(R) + 3B(S) + 4k + 3B(U) = 75000 + 4k
Example
Query Optimization (49 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (8 of 13)
 
(1) materializing method:  
Cost = 3B(R) + 3B(S) + 4k + 3B(U) 
(2) pipeline method 
Cost = 3B(R) + 3B(S) + B(U) 
(Because the second join result does not 
need to be written into the disk. ) 
(To be continued in the next lecture. ) 
• Smarter:
• Step 1: hash R on x into 100 buckets, each of 50 
blocks; to disk
• Step 2: hash S on x into 100 buckets; to disk
• Step 3: read each Ri in memory (50 buffer) join with 
Si (1 buffer); hash result on y into 50 buckets (50 
buffers)   -- here we pipeline
• Cost so far: 3B(R) + 3B(S)
Example
Query Optimization (50 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (9 of 13)
 
 
• Continuing:
• How large are the 50 buckets on y ?  Answer: k/50.
• If k <= 50 then keep all 50 buckets in Step 3 in 
memory, then:
• Step 4: read U from disk, hash on y and join with 
memory
• Total cost: 3B(R) + 3B(S) + B(U) = 55,000
Example
Query Optimization (51 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (10 of 13)
 
 
• Continuing:
• If 50 < k <= 5000 then send the 50 buckets in Step 3 
to disk
• Each bucket has size k/50 <= 100
• Step 4: partition U into 50 buckets
• Step 5: read each partition and join in memory
• Total cost: 3B(R) + 3B(S) + 2k + 3B(U) = 75,000 + 2k
Example
Query Optimization (52 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (11 of 13)
 
 
• Continuing:
• If k > 5000 then materialize instead of pipeline
• 2 partitioned hash-joins
• Cost 3B(R) + 3B(S) + 4k + 3B(U) = 75000 + 4k
Example
Query Optimization (53 of 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing Physical Query Plan (12 of 13)
 
 
• Summary:
• If k <= 50, cost = 55,000
• If 50 < k <=5000, cost = 75,000 + 2k
• If k > 5000, cost = 75,000 + 4k
Example
Query Optimization (54 of 64)Completing Physical Query Plan (13 of 13)
 
 
Estimating Sizes
Query Optimization (55 of 64)Estimating Sizes (0 of 9)
 
 
• Need size in order to estimate cost
• Example:
• Cost of partitioned hash-join       is         
       
•                          
•                          
• So, we need to estimate            
Estimating Sizes
Query Optimization (56 of 64)Estimating Sizes (1 of 9)
 
 
• Estimating the size of a projection
• Easy:                
• A projection doesn’t eliminate duplicates
Estimating Sizes
Query Optimization (57 of 64)Estimating Sizes (2 of 9)
 
 
• Estimating the size of a selection
•           
• T(S) can be anything from 0 to                  
• Mean value:                   
•           
• T(S) can be anything from 0 to     
• Heuristics:              
Estimating Sizes
Query Optimization (58 of 64)Estimating Sizes (3 of 9)
 
 
• Estimating the size of a natural join,      
• When the set of A values are disjoint, then 
•            
• When A is a key in S and a foreign key in R, then 
             
• When A has a unique value, the same in R and S, 
then               .
Estimating Sizes
Query Optimization (59 of 64)Estimating Sizes (4 of 9)
 
 
• Assumptions:
• Containment of values: if          
         then the set of R.A values is included in 
the set of S.A values
• Indeed holds when A is a foreign key in R, and a key in S
• Preservation of values: for any other attribute  ,  
•             or     .
Estimating Sizes
Query Optimization (60 of 64)Estimating Sizes (5 of 9)
 
 
• Assume                 
• Then each tuple  in  joins some tuple(s) in  
• How many?
• On average         
• It will contribute         tuples in     
• Hence                    
• In general: 
•                            
Estimating Sizes
Query Optimization (61 of 64)Estimating Sizes (6 of 9)
 
 
• Example:
•                          
•                          
• How large is     ?
• Answer: 
•                                
Estimating Sizes
Query Optimization (62 of 64)Estimating Sizes (7 of 9)
 
 
• Joins on more than one attribute:
•       
    
                    
Estimating Sizes
Query Optimization (63 of 64)Estimating Sizes (8 of 9)
 
 
• Statistics on data maintained by the RDBMS
• Makes size estimation much more accurate (hence, 
cost estimations are more accurate)
• Ranks(rankName, salary)
• Estimate the size of                      
More statistics helps: E.g., Histograms
Query Optimization (64 of 64)
Employee 0..20k 20k..40k 40k..60k 60k..80k 80k..100k > 100k
200 800 5000 12000 6500 500
Ranks 0..20k 20k..40k 40k..60k 60k..80k 80k..100k > 100k
8 20 40 80 100 2
Estimating Sizes (9 of 9)
 
 
 
