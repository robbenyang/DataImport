Kevin	 Â C.	 Â Chang
Query Â Optimization
Database	 Â Systems
	 Â 
	 Â 
â€¢ Query	 Â optimization,	 Â query	 Â optimizer
â€¢ Logical	 Â query	 Â plans
â€¢ Algebraic	 Â laws	 Â of	 Â equivalence
â€¢ Rule-Â­â€based	 Â optimization,	 Â Heuristic
â€¢ Cost-Â­â€based	 Â optimization
â€¢ Join	 Â trees
â€¢ Dynamic	 Â programming
â€¢ Physical	 Â query	 Â plans
â€¢ Intermediate	 Â results,	 Â pipeline,	 Â materialization
â€¢ Estimating	 Â sizes
Concepts	 Â You	 Â Will	 Â Learn
Query	 Â Optimization	 Â (1	 Â of	 Â 64)Default	 Â Section	 Â (1	 Â of	 Â 2) 	 Â 
This	 Â is	 Â the	 Â concept	 Â road	 Â map	 Â 
The Â Big Â Picture: Â Where Â We Â Are
Query Â Optimization Â (2 Â of Â 64)
Data	 Â Access
Data	 Â Modeling
Data/Query	 Â Processing
Data	 Â Acquisition
Relational NonRelational
St
ru
ct
ur
ed
Se
m
iS
tr
uc
tu
re
d
Transaction	 Â Management
N
oS
Q
L Â 
D
at
ab
as
es
XM
L Â 
D
at
ab
as
es
U
nt
ru
ct
ur
ed
Relational Â Databases
â€¢ SQL
â€¢ Relational Â Algebra
â€¢ Query Â Optimization
â€¢ Query Â Execution
â€¢ Indexing
â€¢ Concurrency Â Control
â€¢ Logging Â Recovery
Database Â Systems Toolkits
M
ap
 Â R
ed
uc
e
(P
ar
al
le
l)
St
or
m
 Â 
(S
tr
ea
m
)
Information Â Extraction
ER Â Ã ïƒ  Relational Â Model
Query	 Â Language
Default Â Section Â (2 Â of Â 2) 	 Â 
Reviews	 Â from	 Â previous	 Â few	 Â lectures:	 Â 
â€¢ Indexing:	 Â Given	 Â value	 Â or	 Â keyword,	 Â 
how	 Â to	 Â find	 Â them	 Â on	 Â disk.	 Â 
â€¢ Query	 Â Execution:	 Â Concept	 Â of	 Â 
cost,	 Â requirements	 Â of	 Â memory.	 Â 
â€¢ One-Â­â€pass	 Â Algorithm:	 Â Process	 Â 
relation	 Â once	 Â (more	 Â memory	 Â 
required).	 Â 
â€¢ Two-Â­â€pass	 Â Algorithm:	 Â 1.Organize	 Â 
data	 Â by	 Â hash/sorted	 Â list	 Â 2.	 Â Process	 Â 
query.	 Â 
â€¢ Zero-Â­â€pass:	 Â using	 Â index.	 Â 
From	 Â now:	 Â 
â€¢ Query	 Â optimizer:	 Â Generate	 Â 
strategic	 Â plan	 Â when	 Â got	 Â the	 Â 
query.	 Â The	 Â quality	 Â of	 Â the	 Â plan	 Â 
determines	 Â the	 Â efficiency	 Â of	 Â 
query	 Â execution.	 Â 
Why	 Â Do	 Â We	 Â Learn	 Â This?
Query Â Optimization Â (3 Â of Â 64)Why Â Do Â We Â Learn Â This? Â (0 Â of Â 0) 	 Â 
The	 Â performance	 Â is	 Â very	 Â important	 Â 
Three	 Â most	 Â important	 Â factors	 Â in	 Â DB:	 Â 
1. Performance	 Â 
2. Reliability	 Â 	 Â 
3. High	 Â level	 Â declarative	 Â 
	 Â TPC:	 Â Use	 Â database	 Â plus	 Â 	 Â hardware	 Â to	 Â test	 Â 
the	 Â speed	 Â of	 Â database.	 Â 
Overview
Query Â Optimization Â (4 Â of Â 64)Overview Â (0 Â of Â 5) 	 Â 
	 Â 
â€¢ At	 Â the	 Â heart	 Â of	 Â the	 Â database	 Â engine
â€¢ Step	 Â 1:	 Â convert	 Â the	 Â SQL	 Â query	 Â to	 Â some	 Â logical	 Â plan
â€¢ Step	 Â 2:	 Â find	 Â a	 Â better	 Â logical	 Â plan,	 Â find	 Â an	 Â associated	 Â 
physical	 Â plan
Optimization
Query	 Â Optimization	 Â (5	 Â of	 Â 64)Overview	 Â (1	 Â of	 Â 5) 	 Â 
â€¢ Logical	 Â plan:	 Â Relational	 Â algebra	 Â 
level,	 Â different	 Â operations	 Â are	 Â 
only	 Â defined	 Â by	 Â their	 Â input	 Â and	 Â 
output,	 Â e.g.	 Â join,	 Â selection,	 Â etc.	 Â 
â€¢ Physical	 Â plan:	 Â Implementation	 Â 
level,	 Â e.g.	 Â hash-Â­â€based	 Â join,	 Â index-Â­â€
based	 Â join.	 Â 
â€¢ We	 Â now	 Â focus	 Â on	 Â Physical	 Â Plan	 Â 
SELECT	 Â a1,	 Â â€¦,	 Â an
FROM	 Â R1,	 Â â€¦,	 Â Rk
WHERE	 Â Cğœ‹ğ‘#, â€¦ , ğ‘&(ğœğ¶ Â (ğ‘…# Ã— Â  Â ğ‘…- Ã— â‹¯Ã— ğ‘…/))
Converting	 Â from	 Â SQL	 Â to	 Â Logical	 Â Plans
Query	 Â Optimization	 Â (6	 Â of	 Â 64)Overview	 Â (2	 Â of	 Â 5) 	 Â 
The	 Â lower	 Â part	 Â of	 Â the	 Â slide	 Â is	 Â already	 Â a	 Â 
query	 Â plan,	 Â but	 Â it	 Â is	 Â not	 Â efficiency	 Â because	 Â 
Cartesian	 Â product	 Â combines	 Â everything	 Â 
with	 Â anything	 Â which	 Â is	 Â often	 Â not	 Â 
necessary.	 Â 
â€¢ Now	 Â we	 Â have	 Â one	 Â logical	 Â plan
â€¢ Algebraic	 Â laws:
â€¢ foundation	 Â for	 Â every	 Â optimization
â€¢ Two	 Â approaches	 Â to	 Â optimizations:
â€¢ Rule-Â­â€based	 Â (heuristics): apply	 Â laws	 Â that	 Â seem	 Â to	 Â result	 Â in	 Â 
cheaper	 Â plans
â€¢ Cost-Â­â€based:	 Â estimate	 Â size	 Â and	 Â cost	 Â of	 Â intermediate	 Â 
results,	 Â search	 Â systematically	 Â for	 Â best	 Â plan
Optimization:	 Â Logical	 Â Query	 Â Plan
Query	 Â Optimization	 Â (7	 Â of	 Â 64)Overview	 Â (3	 Â of	 Â 5) 	 Â 
1. Algebraic	 Â laws	 Â gives	 Â the	 Â equivalence	 Â 
plan.	 Â 	 Â 
Rule-Â­â€Base	 Â Optimizer	 Â (RBO):	 Â See	 Â more	 Â 
from	 Â Oracleâ€™s	 Â documentation	 Â 
http://docs.oracle.com/cd/B10500_01/se
rver.920/a96533/rbo.htm	 Â 
2. Cost	 Â based	 Â are	 Â design	 Â according	 Â to	 Â 
better	 Â run	 Â times.	 Â The	 Â cost	 Â to	 Â run	 Â the	 Â 
same	 Â query	 Â may	 Â be	 Â different	 Â from	 Â time	 Â to	 Â 	 Â 
time.	 Â 
Cost-Â­â€Based	 Â Optimizer	 Â (CBO):	 Â No	 Â fixed	 Â 
rule,	 Â while	 Â believe	 Â in	 Â run-Â­â€time	 Â cost.	 Â See	 Â 
more	 Â http://www.oracle-Â­â€
base.com/articles/misc/cost-Â­â€based-Â­â€
optimizer-Â­â€and-Â­â€database-Â­â€statistics.php	 Â 
3. Heuristics	 Â refers to experience-based 
techniques for problem solving, learning, 
and discovery that give a solution which is 
not guaranteed to be optimal.	 Â 
Select	 Â S.name,	 Â C.instructor
From	 Â Students	 Â S,	 Â Enrollment	 Â E,	 Â Course	 Â C
Where	 Â S.dept =	 Â â€˜CSâ€™	 Â and	 Â 
S.sid=E.sid and	 Â E.cid =	 Â C.cid
Motivating	 Â Example
Query	 Â Optimization	 Â (8	 Â of	 Â 64)Overview	 Â (4	 Â of	 Â 5) 	 Â 
Suppose	 Â we	 Â have	 Â 40k	 Â students,	 Â 1k	 Â 
classes,	 Â 200k	 Â enrollment.	 Â 
	 Â 
1. We	 Â first	 Â join	 Â Students	 Â and	 Â Enrollment,	 Â 
and	 Â then	 Â Courses.	 Â 	 Â 
2. For	 Â second	 Â diagram.	 Â Because	 Â we	 Â only	 Â 
care	 Â about	 Â students	 Â in	 Â CS,	 Â we	 Â can	 Â first	 Â 
select	 Â the	 Â cs	 Â students	 Â from	 Â Students	 Â then	 Â 
join	 Â with	 Â Enrollment.	 Â The	 Â query	 Â can	 Â be	 Â 
optimized.	 Â 
3. For	 Â example	 Â on	 Â the	 Â third	 Â diagram,	 Â If	 Â we	 Â 
have	 Â less	 Â students	 Â in	 Â Summer,	 Â we	 Â will	 Â 
have	 Â less	 Â enrollment	 Â which	 Â would	 Â be	 Â 
optimized	 Â to	 Â join	 Â Enrollment	 Â and	 Â Classes	 Â 
first	 Â then	 Â with	 Â the	 Â Cs	 Â students.	 Â 
All	 Â of	 Â the	 Â above	 Â plans	 Â will	 Â give	 Â the	 Â correct	 Â 
result	 Â because	 Â of	 Â the	 Â algebraic	 Â laws	 Â that	 Â 
we	 Â will	 Â learn	 Â it	 Â in	 Â few	 Â slides.	 Â 
â€¢ We	 Â need	 Â three	 Â things	 Â in	 Â an	 Â optimizer:
â€¢ Algebraic	 Â laws
â€¢ A	 Â cost	 Â estimator
â€¢ An	 Â optimization	 Â algorithm
The	 Â three	 Â components	 Â of	 Â an	 Â optimizer
Query	 Â Optimization	 Â (9	 Â of	 Â 64)Overview	 Â (5	 Â of	 Â 5) 	 Â 
1. Algebraic	 Â laws	 Â tell	 Â us	 Â the	 Â possible	 Â 
plans.	 Â 
2. A	 Â cost	 Â estimator	 Â tells	 Â us	 Â the	 Â cost	 Â of	 Â 
each	 Â plan.	 Â 
3. Optimization	 Â algorithm	 Â can	 Â help	 Â us	 Â find	 Â 
the	 Â most	 Â efficient	 Â plan(P*).	 Â 
Algebraic	 Â Laws
Query Â Optimization Â (10 Â of Â 64)Algebraic Â Laws Â (0 Â of Â 4) 	 Â 
	 Â 
â€¢ Commutative	 Â and	 Â Associative	 Â Laws
â€¢ ğ‘… âˆª ğ‘† Â  =  Â ğ‘† âˆª ğ‘…, ğ‘… âˆª (ğ‘† âˆª ğ‘‡)  Â =  Â  (ğ‘… âˆª ğ‘†) âˆª ğ‘‡
â€¢ ğ‘… Â  âˆ©  Â ğ‘† Â  =  Â ğ‘† Â  âˆ©  Â ğ‘…, ğ‘… Â  âˆ© Â (ğ‘† Â  âˆ©  Â ğ‘‡)  Â =  Â  (ğ‘… Â  âˆ©  Â ğ‘†)  Â âˆ©  Â ğ‘‡
â€¢ ğ‘… Â  â‹ˆ  Â ğ‘† Â  =  Â ğ‘† Â  â‹ˆ  Â ğ‘…, ğ‘… Â  â‹ˆ  Â  (ğ‘† Â  â‹ˆ  Â ğ‘‡)  Â =  Â  (ğ‘… Â  â‹ˆ  Â ğ‘†)  Â â‹ˆ  Â ğ‘‡
â€¢ Distributive	 Â Laws
â€¢ ğ‘… Â  â‹ˆ  Â  (ğ‘† âˆª ğ‘‡)  Â  Â =  Â  Â  (ğ‘… Â  â‹ˆ  Â ğ‘†) âˆª (ğ‘… Â  â‹ˆ  Â ğ‘‡)
Algebraic	 Â Laws
Query	 Â Optimization	 Â (11	 Â of	 Â 64)
Q:	 Â How	 Â to	 Â prove	 Â these	 Â laws?
Algebraic	 Â Laws	 Â (1	 Â of	 Â 4) 	 Â 
If	 Â we	 Â want	 Â to	 Â prove	 Â these	 Â laws	 Â we	 Â need	 Â 
to	 Â show	 Â tuples	 Â belongs	 Â to	 Â LHS	 Â if	 Â and	 Â only	 Â 
if	 Â tuples	 Â belongs	 Â to	 Â RHS.	 Â 
â€¢ Laws	 Â involving	 Â selection:
â€¢  Â ğœ# Â $%& Â #' Â (ğ‘…)  Â = ğœ#(ğœ#, Â  ğ‘… ) = ğœ#(ğ‘…)  Â âˆ© ğœ#'(ğ‘…)
â€¢ ğœ# Â ./ Â #' Â  ğ‘… = ğœ# ğ‘… âˆª ğœ#'(ğ‘…)
â€¢ ğœ# Â (ğ‘… Â  â‹ˆ  Â ğ‘†)  Â = ğœ# ğ‘… â‹ˆ  Â ğ‘† Â 
â€¢ When	 Â C	 Â involves	 Â only	 Â attributes	 Â of	 Â R
â€¢ ğœ# Â  ğ‘… Â  âˆ’  Â ğ‘† = ğœ# ğ‘… âˆ’  Â ğ‘† Â 
â€¢ ğœ# Â  ğ‘… âˆª ğ‘† = ğœ# ğ‘… âˆª ğ‘†
â€¢ ğœ# ğ‘… Â  âˆ©  Â ğ‘†  Â = ğœ# ğ‘… âˆ©  Â ğ‘†
â€¢ Q:	 Â What	 Â do	 Â they	 Â mean?	 Â Make	 Â sense?
Algebraic	 Â Laws
Query	 Â Optimization	 Â (12	 Â of	 Â 64)Algebraic	 Â Laws	 Â (2	 Â of	 Â 4) 	 Â 
With	 Â these	 Â laws	 Â we	 Â can	 Â push	 Â selection	 Â 
down.	 Â By	 Â push	 Â down	 Â and	 Â up	 Â we	 Â mean	 Â 
query	 Â trees.	 Â 
We	 Â can	 Â push	 Â down	 Â a	 Â selection	 Â up	 Â in	 Â the	 Â 
tree	 Â to	 Â bottom	 Â to	 Â narrow	 Â down	 Â the	 Â 
results.	 Â 	 Â 
Push	 Â selection	 Â down	 Â is	 Â a	 Â heuristic	 Â rule	 Â 
which	 Â have	 Â a	 Â high	 Â chance	 Â to	 Â be	 Â true	 Â but	 Â 
not	 Â guarantee	 Â to	 Â be	 Â true.	 Â Showing	 Â the	 Â 
fragility	 Â of	 Â RBO	 Â (rule-Â­â€based	 Â optimizer).	 Â 
	 Â 
â€¢ Example:	 Â 	 Â ğ‘…(ğ´, ğµ, ğ¶, ğ·), ğ‘†(ğ¸, ğ¹, ğº)
â€¢  Â ğœ/01 Â (ğ‘… Â  â‹ˆ304 ğ‘†)  Â = Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ?
â€¢  Â ğœ708 Â 793 Â :0; Â (ğ‘… â‹ˆ304 ğ‘†)  Â = Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ?
Algebraic	 Â Laws
Query	 Â Optimization	 Â (13	 Â of	 Â 64)Algebraic	 Â Laws	 Â (3	 Â of	 Â 4) 	 Â 
(a) Because	 Â S	 Â have	 Â attribute	 Â F,	 Â 	 Â we	 Â push	 Â 
selection	 Â to	 Â S	 Â which	 Â becomes	 Â R	 Â natural	 Â 
join	 Â selection	 Â of	 Â S.	 Â 
(b) Same	 Â for	 Â b.	 Â Because	 Â A	 Â belong	 Â to	 Â R	 Â and	 Â 
G	 Â belongs	 Â to	 Â A,	 Â selection	 Â of	 Â A=5	 Â push	 Â to	 Â R	 Â 
and	 Â selection	 Â of	 Â G=9	 Â push	 Â to	 Â S.	 Â 
â€¢ Laws	 Â involving	 Â projections
â€¢  Â ğœ‹#(ğ‘… Â  â‹ˆ  Â ğ‘†)  Â = ğœ‹*(ğœ‹+(ğ‘…)  Â â‹ˆ ğœ‹,(ğ‘†))
â€¢ Where	 Â N,	 Â P,	 Â Q	 Â are	 Â appropriate	 Â subsets	 Â of	 Â attributes	 Â of	 Â M
â€¢  Â  Â ğœ‹#(ğœ‹*(ğ‘…))  Â =  Â ğœ‹#âˆ©*(ğ‘…)
â€¢ Example	 Â ğ‘…(ğ´, ğµ, ğ¶, ğ·), ğ‘†(ğ¸, ğ¹, ğº)
â€¢ ğœ‹6,7,8(ğ‘… â‹ˆ9:; ğ‘†)  Â = ğœ‹? Â (ğœ‹?(ğ‘…)  Â â‹ˆ ğœ‹?(ğ‘†)) Â 
Algebraic	 Â Laws
Query	 Â Optimization	 Â (14	 Â of	 Â 64)Algebraic	 Â Laws	 Â (4	 Â of	 Â 4) 	 Â 
The	 Â first	 Â ?	 Â should	 Â be	 Â ABG	 Â because	 Â we	 Â 
need	 Â them.	 Â 
The	 Â second	 Â ?	 Â should	 Â be	 Â AB	 Â because	 Â we	 Â 
need	 Â them	 Â and	 Â D	 Â because	 Â we	 Â need	 Â it	 Â to	 Â 
join.	 Â 
Same	 Â for	 Â third	 Â ?.	 Â It	 Â should	 Â be	 Â E	 Â and	 Â G.	 Â G	 Â 
for	 Â projection	 Â and	 Â E	 Â for	 Â join.	 Â 
Optimizer
Query Â Optimization Â (15 Â of Â 64)Optimizer Â (0 Â of Â 2) 	 Â 
	 Â 
Behind Â the Â Scene: Â Oracle Â RBO Â and Â CBO
Query Â Optimization Â (16 Â of Â 64)
â€¢ Oracle 7 (1992) prior (since 1979): RBO.
â€¢ Oracle 7-10: RBO + CBO.
â€¢ Oracle 10g (2003): CBO.
Optimizer Â (1 Â of Â 2) 	 Â 
	 Â 
Behind Â the Â Scene: Â Oracle Â RBO Â and Â CBO
Query Â Optimization Â (17 Â of Â 64)Optimizer Â (2 Â of Â 2) 	 Â 
	 Â 
Rule-Â­â€based	 Â Optimization
Query Â Optimization Â (18 Â of Â 64)Rule-Â­â€based Â Optimization Â (0 Â of Â 3) 	 Â 
	 Â 
â€¢ Query	 Â rewriting	 Â based	 Â on	 Â heuristic/algebraic	 Â laws
â€¢ Result	 Â in	 Â better	 Â queries	 Â most	 Â of	 Â the	 Â time
â€¢ Heuristics	 Â number	 Â 1:
â€¢ Push	 Â selections	 Â down
â€¢ Heuristics	 Â number	 Â 2:
â€¢ Sometimes	 Â push	 Â selections	 Â up,	 Â then	 Â down
Ruler-Â­â€ased	 Â Optimizations
Query	 Â Optimization	 Â (19	 Â of	 Â 64)Rule-Â­â€based	 Â Optimization	 Â (1	 Â of	 Â 3) 	 Â 
Push	 Â selection	 Â down	 Â and	 Â up	 Â are	 Â all	 Â rules.	 Â 
Predicate Â Pushdown
Product Company
ğˆğ’‘ğ’“ğ’Šğ’„ğ’†'ğŸğŸğŸ Â ğ‘¨ğ‘µğ‘« Â ğ’„ğ’Šğ’•ğ’š0"ğ‘¼ğ’“ğ’ƒğ’‚ğ’ğ’‚"
ğ…ğ’‘ğ’ğ’‚ğ’ğ’†
â‹ˆ9:;<=0>?:9<
Product(pname, Â maker, Â price) Company(cname, Â city)
Rule-Â­â€based Â Optimization Â (2 Â of Â 3) Query Â Optimization Â (20 Â of Â 64) 	 Â 
We	 Â can	 Â push	 Â price	 Â >	 Â 100	 Â down	 Â to	 Â product	 Â 
and	 Â city=â€Urbanaâ€	 Â down	 Â to	 Â Company.	 Â 
But	 Â this	 Â is	 Â not	 Â always	 Â make	 Â sense,	 Â if	 Â 
companies	 Â in	 Â Urbana	 Â do	 Â not	 Â have	 Â 
products	 Â higher	 Â than	 Â 100.	 Â 
This	 Â is	 Â when	 Â we	 Â need	 Â cost-Â­â€based	 Â 
optimization.	 Â 
Cost-Â­â€based	 Â Optimization
Query Â Optimization Â (22 Â of Â 64)Cost-Â­â€based Â Optimization Â (0 Â of Â 5) 	 Â 
	 Â 
Behind Â the Â Scene: Â The Â Selinger Â Style!
Query Â Optimization Â (23 Â of Â 64)Cost-Â­â€based Â Optimization Â (1 Â of Â 5) 	 Â 
	 Â 
Behind Â the Â Scene: Â The Â Selinger Â Style!
Query Â Optimization Â (24 Â of Â 64)Cost-Â­â€based Â Optimization Â (2 Â of Â 5) 	 Â 
	 Â 
â€¢ Main	 Â idea:	 Â apply	 Â algebraic	 Â laws,	 Â until	 Â estimated	 Â 
cost	 Â is	 Â minimal
â€¢ Practically:	 Â start	 Â from	 Â partial	 Â plans,	 Â introduce	 Â 
operators	 Â one	 Â by	 Â one
â€¢ Will	 Â see	 Â in	 Â a	 Â few	 Â slides
â€¢ Problem:	 Â there	 Â are	 Â too	 Â many	 Â ways	 Â to	 Â apply	 Â the	 Â 
laws,	 Â hence	 Â too	 Â many	 Â (partial)	 Â plans
Cost-Â­â€based	 Â Optimization
Query	 Â Optimization	 Â (25	 Â of	 Â 64)Cost-Â­â€based	 Â Optimization	 Â (3	 Â of	 Â 5) 	 Â 
â€¢ Apply	 Â algebraic	 Â laws	 Â until	 Â the	 Â 
estimated	 Â cost	 Â is	 Â minimal.	 Â Use	 Â 
optimization	 Â algorithm	 Â to	 Â guide	 Â 
this	 Â application	 Â of	 Â laws,	 Â look	 Â at	 Â 
different	 Â plans	 Â exhaustively	 Â and	 Â 
find	 Â out	 Â the	 Â most	 Â optimal	 Â one.	 Â 
â€¢ It	 Â now	 Â becomes	 Â a	 Â standard	 Â search	 Â 
problem.	 Â 
â€¢ Approaches:
â€¢ Top-Â­â€down:	 Â the	 Â partial	 Â plan	 Â is	 Â a	 Â top	 Â fragment	 Â of	 Â the	 Â 
logical	 Â plan
â€¢ Bottom	 Â up:	 Â the	 Â partial	 Â plan	 Â is	 Â a	 Â bottom	 Â fragment	 Â of	 Â 
the	 Â logical	 Â plan
Cost-Â­â€based	 Â Optimization
Query	 Â Optimization	 Â (26	 Â of	 Â 64)Cost-Â­â€based	 Â Optimization	 Â (4	 Â of	 Â 5) 	 Â 
Top	 Â down	 Â means	 Â to	 Â build	 Â the	 Â trees	 Â from	 Â 
the	 Â root.	 Â 	 Â 
Bottom	 Â up	 Â means	 Â to	 Â build	 Â the	 Â trees	 Â from	 Â 
the	 Â leaves.	 Â 
	 Â 
â€¢ Branch-Â­â€and-Â­â€bound:
â€¢ Remember	 Â the	 Â cheapest	 Â complete	 Â plan	 Â P	 Â seen	 Â so	 Â far	 Â and	 Â 
its	 Â cost	 Â C
â€¢ Stop	 Â generating	 Â partial	 Â plans	 Â whose	 Â cost	 Â is	 Â >	 Â C
â€¢ If	 Â a	 Â cheaper	 Â complete	 Â plan	 Â is	 Â found,	 Â replace	 Â P,	 Â C
â€¢ Hill	 Â climbing:
â€¢ Remember	 Â only	 Â the	 Â cheapest	 Â partial	 Â plan	 Â seen	 Â so	 Â far
â€¢ Dynamic	 Â programming:
â€¢ Remember	 Â the	 Â all	 Â cheapest	 Â partial	 Â plans
Search	 Â Strategies
Query	 Â Optimization	 Â (27	 Â of	 Â 64)Cost-Â­â€based	 Â Optimization	 Â (5	 Â of	 Â 5) 	 Â 
â€¢ Branch-Â­â€and-Â­â€bound	 Â algorithm:	 Â 
http://en.wikipedia.org/wiki/Bran
ch_and_bound	 Â 
â€¢ Hill	 Â climbing:	 Â 
http://en.wikipedia.org/wiki/Hill_
climbing	 Â 
â€¢ Dynamic	 Â programming:	 Â 	 Â 
http://en.wikipedia.org/wiki/Dyn
amic_programming	 Â 
Dynamic	 Â Programming
Query Â Optimization Â (28 Â of Â 64)Dynamic Â Programming Â (0 Â of Â 12) 	 Â 
	 Â 
â€¢ ğ‘…1 Â  â‹ˆ  Â ğ‘…2 Â  â‹ˆ  Â â€¦ .â‹ˆ  Â ğ‘…ğ‘›
â€¢ Join	 Â tree:
â€¢ A	 Â plan	 Â =	 Â a	 Â join	 Â tree
â€¢ A	 Â partial	 Â plan	 Â =	 Â a	 Â subtree of	 Â a	 Â join	 Â tree
Join	 Â Trees
Query	 Â Optimization	 Â (29	 Â of	 Â 64)
R3 R1 R2 R4
Dynamic	 Â Programming	 Â (1	 Â of	 Â 12) 	 Â 
Because	 Â the	 Â database	 Â is	 Â so	 Â large	 Â not	 Â all	 Â 
the	 Â situations	 Â can	 Â be	 Â considered,	 Â we	 Â need	 Â 
to	 Â make	 Â some	 Â assumptions.	 Â 	 Â 	 Â 
In	 Â the	 Â example	 Â on	 Â left,	 Â we	 Â make	 Â an	 Â 
assumption	 Â that	 Â it	 Â only	 Â have	 Â binary	 Â join.	 Â 
This	 Â simplifies	 Â the	 Â space	 Â of	 Â 
implementation.	 Â 
â€¢ Left	 Â deep:
Types	 Â of	 Â Join	 Â Trees
Query	 Â Optimization	 Â (30	 Â of	 Â 64)
R3 R1
R5
R2
R4
Dynamic	 Â Programming	 Â (2	 Â of	 Â 12) 	 Â 
1. Left	 Â deep	 Â tree	 Â enable	 Â pipeline	 Â easy.	 Â 
Because	 Â every	 Â operators	 Â only	 Â depend	 Â one	 Â 
preceding	 Â operator,	 Â previous	 Â operator	 Â 
finished	 Â something	 Â ,	 Â the	 Â operator	 Â have	 Â 
some	 Â tuples	 Â to	 Â process.	 Â Then	 Â we	 Â can	 Â have	 Â 
a	 Â whole	 Â line	 Â to	 Â process.	 Â 
2. Memory	 Â requirement	 Â is	 Â smaller.	 Â 	 Â We	 Â 
only	 Â process	 Â one	 Â relation	 Â and	 Â add	 Â other	 Â 
relation	 Â to	 Â it	 Â which	 Â means	 Â there	 Â is	 Â only	 Â 
one	 Â working	 Â space.	 Â 
â€¢ Bushy:
Types	 Â of	 Â Join	 Â Trees
Query	 Â Optimization	 Â (31	 Â of	 Â 64)
R3
R1
R2 R4
R5
Dynamic	 Â Programming	 Â (3	 Â of	 Â 12) 	 Â 
1. Difficult	 Â to	 Â pipeline.	 Â In	 Â the	 Â case	 Â on	 Â the	 Â 
left,	 Â we	 Â have	 Â to	 Â make	 Â both	 Â line	 Â below	 Â 
root	 Â to	 Â work	 Â to	 Â make	 Â it	 Â pipeline.	 Â 
2. Need	 Â more	 Â memory.	 Â It	 Â need	 Â to	 Â two	 Â 
working	 Â spaces	 Â to	 Â make	 Â both	 Â operators	 Â 
working.	 Â 
	 Â 
Try	 Â to	 Â avoid	 Â this	 Â structure.	 Â 
â€¢ Right	 Â deep:
Types	 Â of	 Â Join	 Â Trees
Query	 Â Optimization	 Â (32	 Â of	 Â 64)
R3
R1
R5
R2 R4
Dynamic	 Â Programming	 Â (4	 Â of	 Â 12)
	 Â 
â€¢ Symmetric	 Â to	 Â left	 Â deep.	 Â 
â€¢ Same	 Â concept.	 Â 
FYI	 Â 
Left-Â­â€deep	 Â tree:	 Â 
http://protogenist.wordpress.com/ta
g/left-Â­â€deep-Â­â€trees/	 Â 
Left	 Â deep	 Â vs.	 Â bushy:	 Â 
http://jonathanlewis.wordpress.com/
2007/01/24/left-Â­â€deep-Â­â€trees/	 Â 
â€¢ Given:	 Â a	 Â query	 Â 	 Â ğ‘…1 Â  â‹ˆ  Â ğ‘…2 Â  â‹ˆ  Â â€¦  Â â‹ˆ  Â ğ‘…ğ‘›
â€¢ Assume	 Â we	 Â have	 Â a	 Â function	 Â cost()	 Â that	 Â gives	 Â us	 Â the	 Â 
cost	 Â of	 Â every	 Â join	 Â tree
â€¢ Find	 Â the	 Â best	 Â join	 Â tree	 Â for	 Â the	 Â query
Problem
Query	 Â Optimization	 Â (33	 Â of	 Â 64)Dynamic	 Â Programming	 Â (5	 Â of	 Â 12) 	 Â 
Goal:	 Â 	 Â 
1.	 Â find	 Â the	 Â possible	 Â plans;	 Â 	 Â 
2.	 Â find	 Â the	 Â optimal	 Â plan.	 Â (need	 Â a	 Â search	 Â 
algorithm)	 Â 
3.	 Â estimate	 Â the	 Â cost	 Â to	 Â measure	 Â the	 Â 
quality	 Â of	 Â the	 Â plans	 Â 
â€¢ Idea:	 Â for	 Â each	 Â subset	 Â of	 Â  ğ‘…", â€¦ , ğ‘…% , Â compute	 Â the	 Â 
best	 Â plan	 Â for	 Â that	 Â subset
â€¢ In	 Â increasing	 Â order	 Â of	 Â set	 Â cardinality:
â€¢ ğ‘†ğ‘¡ğ‘’ğ‘ Â 1:  Â ğ‘“ğ‘œğ‘Ÿ Â {ğ‘…"}, {ğ‘…2},â€¦ , {ğ‘…%}
â€¢ ğ‘†ğ‘¡ğ‘’ğ‘ Â 2:  Â ğ‘“ğ‘œğ‘Ÿ Â {ğ‘…", ğ‘…2}, {ğ‘…", ğ‘…4},â€¦ , {ğ‘…%5", ğ‘…%}
â€¢ â€¦
â€¢ ğ‘†ğ‘¡ğ‘’ğ‘ Â ğ‘›:  Â ğ‘“ğ‘œğ‘Ÿ Â {ğ‘…",â€¦ , ğ‘…%}
â€¢ For	 Â each	 Â subset	 Â of	 Â  ğ‘…",â€¦ , ğ‘…% ,	 Â also	 Â called	 Â a	 Â subquery,	 Â 
compute	 Â the	 Â following:
â€¢ Size(Q)
â€¢ Best	 Â plan	 Â for	 Â Q:	 Â Plan(Q)
â€¢ Cost	 Â of	 Â that	 Â plan:	 Â Cost(Q)
Dynamic	 Â Programming
Query	 Â Optimization	 Â (34	 Â of	 Â 64)Dynamic	 Â Programming	 Â (6	 Â of	 Â 12) 	 Â 
Here	 Â is	 Â an	 Â assumption	 Â behind	 Â the	 Â 
algorithm:	 Â The	 Â optimization	 Â of	 Â the	 Â small	 Â 
set	 Â is	 Â also	 Â a	 Â subset	 Â of	 Â the	 Â optimization	 Â of	 Â 
the	 Â bigger	 Â tree.	 Â i.e.:	 Â {small	 Â set}*	 Â =	 Â the	 Â 
best	 Â for	 Â the	 Â big	 Â tree.	 Â 	 Â 
Dynamic	 Â Programming	 Â breaks	 Â down	 Â the	 Â 
problem	 Â and	 Â makes	 Â an	 Â incremental	 Â step-Â­â€
by-Â­â€step	 Â optimization.	 Â (The	 Â current	 Â step	 Â is	 Â 
based	 Â on	 Â previous	 Â optimal	 Â result.	 Â )	 Â 
â€¢ To	 Â illustrate,	 Â we	 Â will	 Â make	 Â the	 Â following	 Â 
simplifications:
â€¢ ğ¶ğ‘œğ‘ ğ‘¡(ğ‘ƒ1 Â  â‹ˆ  Â ğ‘ƒ2)  Â =  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘ƒ1)  Â +  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘ƒ2) Â + Â  Â  Â  Â  Â ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ Â ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡)
â€¢ Intermediate	 Â results:
â€¢ If	 Â P1	 Â =	 Â a	 Â join,	 Â then	 Â the	 Â size	 Â of	 Â the	 Â intermediate	 Â result	 Â is	 Â 
size(P1),	 Â otherwise	 Â the	 Â size	 Â is	 Â 0
â€¢ Similarly	 Â for	 Â P2
â€¢ Cost	 Â of	 Â a	 Â scan	 Â =	 Â 0,	 Â i.e.,	 Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘…) Â =	 Â 0.
Dynamic	 Â Programming
Query	 Â Optimization	 Â (35	 Â of	 Â 64)Dynamic	 Â Programming	 Â (7	 Â of	 Â 12) 	 Â 
Example:	 Â 	 Â 
Suppose	 Â P1	 Â is	 Â a	 Â join	 Â between	 Â R1	 Â and	 Â R2	 Â 
and	 Â P2	 Â is	 Â a	 Â single	 Â relation	 Â of	 Â R3.	 Â Then,	 Â 	 Â 
Cost(P1	 Â â‹ˆ	 Â P2)	 Â =	 Â Cost(P1)	 Â +	 Â Cost(P2)	 Â +	 Â 
size(P1)	 Â 
â€¢ Example:
â€¢ ğ¶ğ‘œğ‘ ğ‘¡ ğ‘…1 Â  â‹ˆ  Â ğ‘…2 =  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘…1) Â +  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘…2) Â + Â  Â  Â  Â  Â ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ Â ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡) =	 Â 0
â€¢ ğ¶ğ‘œğ‘ ğ‘¡ ğ‘…1 Â  â‹ˆ  Â ğ‘…2 â‹ˆ  Â ğ‘…3=  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘…1 Â  â‹ˆ  Â ğ‘…2)  Â +  Â ğ¶ğ‘œğ‘ ğ‘¡(ğ‘…3)  Â +  Â ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘…1 Â â‹ˆ  Â ğ‘…2)=  Â ğ‘ ğ‘–ğ‘§ğ‘’(ğ‘…1 Â  â‹ˆ  Â ğ‘…2)
Dynamic	 Â Programming
Query	 Â Optimization	 Â (36	 Â of	 Â 64)Dynamic	 Â Programming	 Â (8	 Â of	 Â 12) 	 Â 
Two	 Â examples	 Â (formulas)	 Â need	 Â to	 Â be	 Â 
supplemented.	 Â 	 Â 
1.	 Â Cost((R1	 Â â‹ˆ R2) â‹ˆ	 Â (R3	 Â â‹ˆ	 Â R4))	 Â 	 Â 
=	 Â Cost(R1	 Â â‹ˆ	 Â R2)	 Â +	 Â Cost(R3	 Â â‹ˆ	 Â R4)	 Â +	 Â Size	 Â 
(R1	 Â â‹ˆ	 Â R2)	 Â +	 Â Size	 Â (R3	 Â â‹ˆ	 Â R4)	 Â 
=	 Â Size	 Â (R1	 Â â‹ˆ	 Â R2)	 Â +	 Â Size	 Â (R3	 Â â‹ˆ	 Â R4)	 Â 	 Â 
(According	 Â to	 Â the	 Â example	 Â of	 Â Cost(R1	 Â â‹ˆ	 Â 
R2)=0)	 Â 
2.	 Â Cost((R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3)	 Â â‹ˆ	 Â R4)	 Â 
=Cost(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3)	 Â +	 Â Cost(R4)	 Â +	 Â 
Size(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3)	 Â 
=	 Â Cost(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3)	 Â +	 Â Size(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â 
R3)	 Â 
(Cost(R4)=0)	 Â 
â€¢ Relations:	 Â ğ‘…, ğ‘†, ğ‘‡, ğ‘ˆ
â€¢ Number	 Â of	 Â tuples:	 Â 2000,	 Â 5000,	 Â 3000,	 Â 1000
â€¢ Size	 Â estimation:	 Â ğ‘‡(ğ´ Â  â‹ˆ  Â ğµ)  Â =  Â 0.01 âˆ— ğ‘‡(ğ´) âˆ— ğ‘‡(ğµ)
Dynamic	 Â Programming
Query	 Â Optimization	 Â (37	 Â of	 Â 64)Dynamic	 Â Programming	 Â (9	 Â of	 Â 12) 	 Â 
The	 Â number	 Â of	 Â tuples	 Â is	 Â defined	 Â as	 Â T(X).	 Â 	 Â 
For	 Â example,	 Â T(R)	 Â =	 Â 2000,	 Â T(S)	 Â =	 Â 5000,	 Â T(T)	 Â 
=3000,	 Â T(U)	 Â =	 Â 1000	 Â 
Example:	 Â 	 Â 
T(R	 Â â‹ˆ	 Â S)	 Â =	 Â 0.01	 Â *	 Â T(R)	 Â *	 Â T(S)	 Â 	 Â 
=0.01*2000*5000	 Â 	 Â 
=	 Â 100k	 Â 
Query Â Optimization Â (38 Â of Â 64)
Subquery Size Cost Plan
RS
RT
RU
ST
SU
TU
RST
RSU
RTU
STU
RSTU
Dynamic Â Programming Â (10 Â of Â 12) 	 Â 
This	 Â is	 Â the	 Â sheet	 Â for	 Â dynamic	 Â 
programming.	 Â 	 Â 
Steps:	 Â 	 Â 
1.	 Â calculate	 Â the	 Â 1-Â­â€relation	 Â subqueries	 Â (R,	 Â 
S,	 Â T,	 Â U);	 Â 	 Â 
2.	 Â calculate	 Â the	 Â 2-Â­â€relation	 Â subqueries	 Â (RS,	 Â 
RTâ€¦);	 Â 	 Â 
3.	 Â calculate	 Â the	 Â 3-Â­â€relation	 Â subqueries	 Â 
(RST,	 Â RTUâ€¦);	 Â 
4.	 Â calculate	 Â the	 Â 4-Â­â€relation	 Â subqueries	 Â 
(RSTU);	 Â 
	 Â 
We	 Â will	 Â fill	 Â it	 Â up	 Â in	 Â the	 Â next	 Â slide.	 Â 	 Â 
Query Â Optimization Â (39 Â of Â 64)
Subquery Size Cost Plan
RS 100k 0 RS
RT 60k 0 RT
RU 20k 0 RU
ST 150k 0 ST
SU 50k 0 SU
TU 30k 0 TU
RST 3M 60k (RT)S
RSU 1M 20k (RU)S
RTU 0.6M 20k (RU)T
STU 1.5M 30k (TU)S
RSTU 30M 60k+50k=110k (RT)(SU)
Dynamic Â Programming Â (11 Â of Â 12) 	 Â 
1.	 Â For	 Â the	 Â subquery	 Â of	 Â RS:	 Â 	 Â 
According	 Â to	 Â the	 Â formula	 Â of	 Â Cost(R1	 Â â‹ˆ	 Â 
R2)	 Â =	 Â 0,	 Â Cost(RS)	 Â =	 Â 0;	 Â 	 Â 
Size(RS)	 Â =	 Â T(R)	 Â *	 Â T(S)	 Â =	 Â 2000	 Â *	 Â 5000	 Â =	 Â 100k	 Â 	 Â 
2.	 Â The	 Â result	 Â of	 Â the	 Â subqueries	 Â of	 Â RT,	 Â RU,	 Â 
ST,	 Â SU,	 Â TU	 Â is	 Â similar	 Â with	 Â that	 Â of	 Â RS.	 Â 	 Â 
3.	 Â For	 Â the	 Â subquery	 Â of	 Â RST:	 Â 	 Â 
There	 Â are	 Â three	 Â possible	 Â plans:	 Â (RS)T,	 Â 
(RT)S,	 Â (ST)R.	 Â 	 Â 
According	 Â to	 Â the	 Â formula	 Â of	 Â Cost((R1	 Â â‹ˆ	 Â 
R2)	 Â â‹ˆ	 Â R3)	 Â =	 Â size(R1	 Â â‹ˆ	 Â R2),	 Â Cost((RS)T)	 Â =	 Â 
size(RS)	 Â =	 Â 100k.	 Â 	 Â 
Similarly,	 Â Cost((RT)S)	 Â =	 Â size(RT)	 Â =	 Â 60k;	 Â 
Cost((ST)R)	 Â =	 Â size(ST)	 Â =	 Â 150k.	 Â 	 Â 
For	 Â smaller	 Â cost,	 Â we	 Â choose	 Â the	 Â plan	 Â of	 Â 
(RT)S.	 Â According	 Â to	 Â the	 Â formula	 Â of	 Â T(A	 Â â‹ˆ	 Â 
B)	 Â =	 Â 0.01	 Â *	 Â T(A)	 Â *	 Â T(B),	 Â the	 Â corresponding	 Â 
size	 Â is	 Â size((RT)S)	 Â =	 Â size(RT)	 Â *	 Â size(S)	 Â =	 Â 0.01	 Â 
*	 Â 60k	 Â *	 Â 5000	 Â =	 Â 3M.	 Â 	 Â 
4.	 Â The	 Â result	 Â of	 Â the	 Â subqueries	 Â of	 Â RSU,	 Â 
RTU	 Â and	 Â STU	 Â is	 Â similar	 Â with	 Â that	 Â of	 Â RST.	 Â 
5.	 Â For	 Â the	 Â subquery	 Â of	 Â RSTU:	 Â 	 Â 
	 Â There	 Â are	 Â seven	 Â possible	 Â plans:	 Â (RST)U,	 Â 
(RSU)T,	 Â (RUT)S,	 Â (STU)R,	 Â (RS)(TU),	 Â (RT)(SU),	 Â 
(RU)(ST).	 Â 	 Â 
According	 Â to	 Â the	 Â formula	 Â of	 Â Cost((R1	 Â â‹ˆ	 Â 
R2	 Â â‹ˆ	 Â R3)	 Â â‹ˆ	 Â R4)	 Â =	 Â Cost(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3)	 Â +	 Â 
Size(R1	 Â â‹ˆ	 Â R2	 Â â‹ˆ	 Â R3),	 Â Cost((RST)U)	 Â =	 Â 
Cost(RST)	 Â +	 Â Size(RST)	 Â =	 Â 3M	 Â +	 Â 60k.	 Â 	 Â 
Similarly,	 Â Cost((RSU)T	 Â )	 Â =1M	 Â +	 Â 20k;	 Â 	 Â 
Cost((RUT)S)	 Â =	 Â 0.6M	 Â +	 Â 20k;	 Â 	 Â 
Cost((STU)R)	 Â =	 Â 1.5M	 Â +	 Â 30k.	 Â 	 Â 
According	 Â to	 Â the	 Â formula	 Â of	 Â Cost((R1	 Â â‹ˆ 
R2) â‹ˆ	 Â (R3	 Â â‹ˆ	 Â R4))	 Â =	 Â Size	 Â (R1	 Â â‹ˆ	 Â R2)	 Â +	 Â Size	 Â 
(R3	 Â â‹ˆ	 Â R4),	 Â Cost((RS)(TU))	 Â =	 Â Size(RS)	 Â +	 Â 
Size(TU)	 Â =	 Â 100k	 Â +	 Â 30k	 Â 	 Â =	 Â 130k.	 Â 	 Â 
Similarly,	 Â Cost((RT)(SU))	 Â =	 Â 110k;	 Â 	 Â 
Cost((RU)(ST))	 Â =	 Â 170k.	 Â 	 Â 
For	 Â smaller	 Â cost,	 Â we	 Â choose	 Â the	 Â plan	 Â of	 Â 
(RT)(SU).	 Â According	 Â to	 Â the	 Â formula	 Â of	 Â T(A	 Â 
â‹ˆ	 Â B)	 Â =	 Â 0.01	 Â *	 Â T(A)	 Â *	 Â T(B),	 Â the	 Â 
corresponding	 Â size	 Â is	 Â size((RT)(SU))	 Â =	 Â 
size(RT)	 Â *	 Â size(SU)	 Â =	 Â 0.01	 Â *	 Â 60k	 Â *	 Â 50k	 Â =	 Â 
30M.	 Â 	 Â 
However,	 Â if	 Â the	 Â final	 Â plan	 Â should	 Â be	 Â a	 Â left	 Â 
deep	 Â tree,	 Â the	 Â plans	 Â of	 Â 	 Â (RS)(TU),	 Â (RT)(SU)	 Â 
and	 Â (RU)(ST)	 Â should	 Â not	 Â be	 Â considered.	 Â 	 Â 
	 Â 
â€¢ Summary:	 Â computes	 Â optimal	 Â plans	 Â for	 Â subqueries:
â€¢ Step	 Â 1:	 Â {R1},	 Â 	 Â {R2},	 Â â€¦,	 Â {Rn}
â€¢ Step	 Â 2:	 Â 	 Â {R1,	 Â R2},	 Â {R1,	 Â R3},	 Â â€¦,	 Â {Rn-Â­â€1,	 Â Rn}
â€¢ â€¦
â€¢ Step	 Â n:	 Â {R1,	 Â â€¦,	 Â Rn}
â€¢ We	 Â used	 Â naÃ¯ve	 Â size/cost	 Â estimations
â€¢ In	 Â practice:
â€¢ more	 Â realistic	 Â size/cost	 Â estimations	 Â (next	 Â time)
â€¢ heuristics	 Â for	 Â Reducing	 Â the	 Â Search	 Â Space	 Â 
â€¢ Restrict	 Â to	 Â left	 Â linear	 Â trees
â€¢ Restrict	 Â to	 Â trees	 Â â€œwithout	 Â Cartesian	 Â productâ€:	 Â 
â€¢ R(A,B),	 Â S(B,C),	 Â T(C,D)
â€¢ (R	 Â join	 Â T)	 Â join	 Â S	 Â has	 Â a	 Â Cartesian	 Â product
Dynamic	 Â Programming
Query	 Â Optimization	 Â (40	 Â of	 Â 64)Dynamic	 Â Programming	 Â (12	 Â of	 Â 12) 	 Â 
The	 Â instructor	 Â skipped	 Â this	 Â slide.	 Â 	 Â 
Completing	 Â Physical	 Â Query	 Â Plan
Query Â Optimization Â (41 Â of Â 64)Completing Â Physical Â Query Â Plan Â (0 Â of Â 13) 	 Â 
	 Â 
â€¢ Choose	 Â algorithm	 Â to	 Â implement	 Â each	 Â operator
â€¢ Need	 Â to	 Â account	 Â for	 Â more	 Â than	 Â cost:
â€¢ How	 Â much	 Â memory	 Â do	 Â we	 Â have	 Â ?
â€¢ Are	 Â the	 Â input	 Â operand(s)	 Â sorted	 Â ?
â€¢ Decide	 Â for	 Â each	 Â intermediate	 Â result:
â€¢ To	 Â materialize
â€¢ To	 Â pipeline
Completing	 Â the	 Â Physical	 Â Query	 Â Plan
Query	 Â Optimization	 Â (42	 Â of	 Â 64)Completing	 Â Physical	 Â Query	 Â Plan	 Â (1	 Â of	 Â 13) 	 Â 
	 Â 
	 Â 
The	 Â difference	 Â between	 Â index-Â­â€based	 Â join	 Â 
and	 Â sort-Â­â€merge	 Â join	 Â 	 Â 
If	 Â memory	 Â is	 Â small,	 Â choose	 Â index-Â­â€based	 Â 
join;	 Â if	 Â memory	 Â is	 Â large,	 Â choose	 Â sort-Â­â€
merge	 Â join.	 Â 	 Â 	 Â 
The	 Â cost	 Â of	 Â index-Â­â€based	 Â join	 Â is	 Â possibly	 Â 
much	 Â larger	 Â than	 Â that	 Â of	 Â sort-Â­â€merge	 Â join.	 Â 
R	 Â â‹ˆ 	 Â S	 Â  index-Â­â€
based	 Â join	 Â 
sort-Â­â€merge	 Â 
join	 Â 
Requireme
nt	 Â 
index	 Â on	 Â 
one	 Â relation	 Â 
N/A	 Â 
Memory	 Â  1	 Â block	 Â of	 Â R,	 Â 
1	 Â block	 Â of	 Â S	 Â 
B(R)B(S)<M2	 Â 
Cost	 Â  B(R)+T(R)B(S
)/V(S,	 Â a)	 Â 
5B(R)+5B(S)	 Â 
â€¢ Material	 Â means	 Â the	 Â intermediate	 Â 
result	 Â will	 Â be	 Â created	 Â whole	 Â and	 Â 
stored	 Â on	 Â disk.	 Â 
â€¢ Pipelined	 Â means	 Â the	 Â intermediate	 Â 
result	 Â will	 Â be	 Â created	 Â only	 Â in	 Â main	 Â 
memory	 Â and	 Â not	 Â necessarily	 Â kept	 Â 
in	 Â their	 Â entirety	 Â at	 Â any	 Â one	 Â time.	 Â 
	 Â 
Materialize Â Intermediate Â Results Â Between Â 
Operators
Query Â Optimization Â (43 Â of Â 64)
â‹ˆ
â‹ˆ
â‹ˆ T
R S
U
HashTable Â ÃŸïƒŸ S
repeat read(R, Â x)
y Â ÃŸïƒŸ join(HashTable, Â x)
write(V1, Â y)
HashTable Â ÃŸïƒŸ T
repeat read(V1, Â y)
z Â ÃŸïƒŸ join(HashTable, Â y)
write(V2, Â z)
HashTable Â ÃŸïƒŸ U
repeat read(V2, Â z)
u Â ÃŸïƒŸ join(HashTable, Â z)
write(Answer, Â u)
V1
V2
Completing Â Physical Â Query Â Plan Â (2 Â of Â 13) 	 Â 
Steps:	 Â 	 Â 
1.	 Â Generate	 Â Hashtable	 Â H(S)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(S);	 Â 	 Â 
2.	 Â Read	 Â every	 Â tuple	 Â of	 Â R	 Â and	 Â join	 Â with	 Â the	 Â 
H(S).	 Â Then	 Â write	 Â into	 Â the	 Â disk.	 Â The	 Â total	 Â 
cost	 Â is	 Â B(R	 Â â‹ˆ	 Â S).	 Â 	 Â 
3.	 Â Generate	 Â Hashtable	 Â H(T)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(T);	 Â 
4.	 Â Read	 Â R	 Â â‹ˆ	 Â S	 Â with	 Â the	 Â cost	 Â of	 Â B(R	 Â â‹ˆ	 Â S)	 Â 
and	 Â then	 Â join	 Â with	 Â H(T).	 Â Then	 Â write	 Â into	 Â 
the	 Â disk	 Â with	 Â the	 Â cost	 Â of	 Â B(R	 Â â‹ˆ	 Â S	 Â â‹ˆ	 Â T).	 Â 	 Â 
5.	 Â Generate	 Â Hashtable	 Â H(U)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(U);	 Â 
6.	 Â Read	 Â R	 Â â‹ˆ	 Â S	 Â â‹ˆ	 Â T	 Â with	 Â the	 Â cost	 Â of	 Â B(R	 Â â‹ˆ	 Â 
S	 Â â‹ˆ	 Â T)	 Â and	 Â then	 Â join	 Â with	 Â H(U).	 Â Then	 Â 
output	 Â the	 Â result.	 Â 	 Â 
The	 Â total	 Â cost	 Â and	 Â the	 Â memory	 Â will	 Â be	 Â 
shown	 Â in	 Â the	 Â next	 Â slide.	 Â 	 Â 
â€¢ Given	 Â B(R),	 Â B(S),	 Â B(T),	 Â B(U)
â€¢ What	 Â is	 Â the	 Â total	 Â cost	 Â of	 Â the	 Â plan	 Â ?
â€¢ Cost	 Â =	 Â 
â€¢ How	 Â much	 Â main	 Â memory	 Â do	 Â we	 Â need	 Â ?
â€¢ M	 Â =	 Â 
Materialize	 Â Intermediate	 Â Results	 Â Between	 Â 
Operators
Query	 Â Optimization	 Â (44	 Â of	 Â 64)Completing	 Â Physical	 Â Query	 Â Plan	 Â (3	 Â of	 Â 13) 	 Â 
As	 Â the	 Â steps	 Â shown	 Â in	 Â the	 Â previous	 Â slide,	 Â 	 Â 
Cost	 Â =	 Â B(R)	 Â +	 Â B(S)	 Â +	 Â B(T)	 Â +	 Â B(U)	 Â +	 Â 2*B(R	 Â â‹ˆ	 Â 
S)	 Â +	 Â B(R	 Â â‹ˆ	 Â S	 Â â‹ˆ	 Â T).	 Â 
Memory	 Â =	 Â Max(B(S),	 Â B(T),	 Â B(U)).	 Â 	 Â 
(As	 Â only	 Â one	 Â tuple	 Â is	 Â read	 Â each	 Â time,	 Â B(R)	 Â 
should	 Â not	 Â be	 Â included	 Â when	 Â calculating	 Â 
the	 Â memory)	 Â 
Pipeline Â Between Â Operators
Query Â Optimization Â (45 Â of Â 64)
â‹ˆ
â‹ˆ
â‹ˆ T
R S
U
HashTable1 Â ÃŸïƒŸ S
HashTable2 Â ÃŸïƒŸ T
HashTable3 Â ÃŸïƒŸ U
repeat read(R, Â x)
y Â ÃŸïƒŸ join(HashTable1, Â x) Â 
z Â ÃŸïƒŸ join(HashTable2, Â y)
u Â ÃŸïƒŸ join(HashTable3, Â z)
write(Answer, Â u)
How Â much Â main Â memory Â do Â we Â need Â ? Â M Â =
Completing Â Physical Â Query Â Plan Â (4 Â of Â 13) 	 Â 
Steps:	 Â 	 Â 
1.	 Â Generate	 Â Hashtable	 Â H(S)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(S);	 Â 
2.	 Â Generate	 Â Hashtable	 Â H(T)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(T);	 Â 
3.	 Â Generate	 Â Hashtable	 Â H(U)	 Â with	 Â the	 Â cost	 Â 
of	 Â B(U);	 Â 
4.	 Â Read	 Â every	 Â tuple	 Â of	 Â R	 Â and	 Â join	 Â with	 Â 
H(S).	 Â Then	 Â join	 Â with	 Â H(T).	 Â Then	 Â join	 Â with	 Â 
H(U)	 Â Then	 Â output	 Â the	 Â answer.	 Â 	 Â 
	 Â 
â€¢ Given	 Â B(R),	 Â B(S),	 Â B(T),	 Â B(U)
â€¢ What	 Â is	 Â the	 Â total	 Â cost	 Â of	 Â the	 Â plan	 Â ?
â€¢ Cost	 Â =	 Â 
â€¢ How	 Â much	 Â main	 Â memory	 Â do	 Â we	 Â need	 Â ?
â€¢ M	 Â =	 Â 
Pipeline	 Â Between	 Â Operators
Query	 Â Optimization	 Â (46	 Â of	 Â 64)Completing	 Â Physical	 Â Query	 Â Plan	 Â (5	 Â of	 Â 13) 	 Â 
As	 Â the	 Â steps	 Â shown	 Â in	 Â the	 Â previous	 Â slide,	 Â 	 Â 
Cost	 Â =	 Â B(R)	 Â +	 Â B(S)	 Â +	 Â B(T)+	 Â B(U).	 Â 	 Â 
Memory	 Â =	 Â B(S)	 Â +	 Â B(T)	 Â +	 Â B(U).	 Â 	 Â 
(The	 Â instructor	 Â wrote	 Â B(S)	 Â +	 Â B(R)	 Â +	 Â B(T),	 Â 
but	 Â I	 Â think	 Â it	 Â should	 Â be	 Â wrong.	 Â )	 Â 
Compared	 Â with	 Â the	 Â Materializing	 Â method,	 Â 
the	 Â pipeline	 Â method	 Â does	 Â not	 Â need	 Â to	 Â 
write	 Â the	 Â result	 Â into	 Â the	 Â disk	 Â during	 Â the	 Â 
procedure	 Â and	 Â therefore	 Â occupies	 Â more	 Â 
memory.	 Â 	 Â 
â€¢ Choose	 Â algorithm	 Â to	 Â implement	 Â each	 Â operator
â€¢ Need	 Â to	 Â account	 Â for	 Â more	 Â than	 Â cost:
â€¢ How	 Â much	 Â memory	 Â do	 Â we	 Â have	 Â ?
â€¢ Are	 Â the	 Â input	 Â operand(s)	 Â sorted	 Â ?
â€¢ Decide	 Â for	 Â each	 Â intermediate	 Â result:
â€¢ To	 Â materialize
â€¢ To	 Â pipeline
Completing	 Â the	 Â Physical	 Â Query	 Â Plan
Query	 Â Optimization	 Â (47	 Â of	 Â 64)Completing	 Â Physical	 Â Query	 Â Plan	 Â (6	 Â of	 Â 13) 	 Â 
	 Â The	 Â instructor	 Â skipped	 Â this	 Â slide.	 Â 
â€¢ Logical	 Â plan	 Â is:
â€¢ Main	 Â memory	 Â M	 Â =	 Â 101	 Â buffers
Example
Query	 Â Optimization	 Â (48	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (7	 Â of	 Â 13) 	 Â 
In	 Â the	 Â 101	 Â buffers,	 Â 1	 Â should	 Â be	 Â hold	 Â for	 Â 
input	 Â buffer.	 Â 	 Â 
If	 Â k	 Â is	 Â very	 Â big,	 Â we	 Â should	 Â use	 Â 
materializing,	 Â because	 Â we	 Â need	 Â to	 Â write	 Â 
the	 Â bucket	 Â out;	 Â If	 Â k	 Â is	 Â very	 Â small,	 Â we	 Â could	 Â 
use	 Â pipeline	 Â method,	 Â because	 Â we	 Â could	 Â 
save	 Â the	 Â bucket	 Â into	 Â the	 Â memory.	 Â 	 Â 
â€¢ NaÃ¯ve	 Â evaluation:	 Â 
â€¢ 2	 Â partitioned	 Â hash-Â­â€joins
â€¢ Cost	 Â 3B(R)	 Â +	 Â 3B(S)	 Â +	 Â 4k	 Â +	 Â 3B(U)	 Â =	 Â 75000	 Â +	 Â 4k
Example
Query	 Â Optimization	 Â (49	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (8	 Â of	 Â 13) 	 Â 
R,	 Â S,	 Â U	 Â can	 Â all	 Â be	 Â hashed	 Â because	 Â blocks	 Â 
of	 Â R,S,U	 Â <=	 Â M^2=10000	 Â 
NaÃ¯ve	 Â method:	 Â simply	 Â do	 Â fully	 Â 
materialization	 Â on	 Â intermediate	 Â result	 Â 
into	 Â disk	 Â without	 Â considering	 Â how	 Â big	 Â K	 Â is.	 Â 
3B(R)	 Â because	 Â we	 Â read	 Â once,	 Â write	 Â once	 Â 
and	 Â read	 Â it	 Â back	 Â to	 Â memory	 Â for	 Â joining,	 Â 
same	 Â as	 Â 3B(S)	 Â and	 Â 3B(U).	 Â 
4K:	 Â read	 Â and	 Â write	 Â out	 Â all	 Â the	 Â K	 Â we	 Â just	 Â 
joined,	 Â then	 Â we	 Â read	 Â it	 Â once	 Â and	 Â twice	 Â for	 Â 
writing	 Â out	 Â the	 Â hash	 Â bucket,	 Â then	 Â bring	 Â 
back	 Â to	 Â memory.	 Â 
â€¢ Smarter:
â€¢ Step	 Â 1:	 Â hash	 Â R	 Â on	 Â x	 Â into	 Â 100	 Â buckets,	 Â each	 Â of	 Â 50	 Â 
blocks;	 Â to	 Â disk
â€¢ Step	 Â 2:	 Â hash	 Â S	 Â on	 Â x	 Â into	 Â 100	 Â buckets;	 Â to	 Â disk
â€¢ Step	 Â 3:	 Â read	 Â each	 Â Ri in	 Â memory	 Â (50	 Â buffer)	 Â join	 Â with	 Â 
Si	 Â (1	 Â buffer);	 Â hash	 Â result	 Â on	 Â y	 Â into	 Â 50	 Â buckets	 Â (50	 Â 
buffers)	 Â 	 Â 	 Â -Â­â€-Â­â€ here	 Â we	 Â pipeline
â€¢ Cost	 Â so	 Â far:	 Â 3B(R)	 Â +	 Â 3B(S)
Example
Query	 Â Optimization	 Â (50	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (9	 Â of	 Â 13) 	 Â 
3B(R)	 Â +	 Â 3B(S)	 Â cannot	 Â be	 Â reduced,	 Â we	 Â will	 Â 
try	 Â to	 Â reduce	 Â 4K	 Â and	 Â 3B(U)	 Â with	 Â new	 Â 
method	 Â depending	 Â on	 Â the	 Â value	 Â of	 Â K.	 Â 
	 Â 
â€¢ Continuing:
â€¢ How	 Â large	 Â are	 Â the	 Â 50	 Â buckets	 Â on	 Â y	 Â ?	 Â 	 Â Answer:	 Â k/50.
â€¢ If	 Â k	 Â <=	 Â 50	 Â then	 Â keep	 Â all	 Â 50	 Â buckets	 Â in	 Â Step	 Â 3	 Â in	 Â 
memory,	 Â then:
â€¢ Step	 Â 4:	 Â read	 Â U	 Â from	 Â disk,	 Â hash	 Â on	 Â y	 Â and	 Â join	 Â with	 Â 
memory
â€¢ Total	 Â cost:	 Â 3B(R)	 Â +	 Â 3B(S)	 Â +	 Â B(U)	 Â =	 Â 55,000
Example
Query	 Â Optimization	 Â (51	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (10	 Â of	 Â 13) 	 Â 
If	 Â K	 Â is	 Â really	 Â small,	 Â we	 Â can	 Â neglect	 Â its	 Â 
contribution.	 Â Like	 Â 50	 Â blocks	 Â can	 Â be	 Â fitted	 Â 	 Â 
into	 Â memory	 Â right	 Â away	 Â by	 Â hashing	 Â the	 Â 
entire	 Â k	 Â values.	 Â Read	 Â U	 Â only	 Â once	 Â per	 Â time	 Â 
because	 Â K	 Â is	 Â small.	 Â 	 Â Besides	 Â k	 Â never	 Â needs	 Â 
to	 Â be	 Â kicked	 Â out	 Â of	 Â the	 Â memory.	 Â 
â€¢ Continuing:
â€¢ If	 Â 50	 Â <	 Â k	 Â <=	 Â 5000	 Â then	 Â send	 Â the	 Â 50	 Â buckets	 Â in	 Â Step	 Â 3	 Â 
to	 Â disk
â€¢ Each	 Â bucket	 Â has	 Â size	 Â k/50	 Â <=	 Â 100
â€¢ Step	 Â 4:	 Â partition	 Â U	 Â into	 Â 50	 Â buckets
â€¢ Step	 Â 5:	 Â read	 Â each	 Â partition	 Â and	 Â join	 Â in	 Â memory
â€¢ Total	 Â cost:	 Â 3B(R)	 Â +	 Â 3B(S)	 Â +	 Â 2k	 Â +	 Â 3B(U)	 Â =	 Â 75,000	 Â +	 Â 2k
Example
Query	 Â Optimization	 Â (52	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (11	 Â of	 Â 13) 	 Â 
When	 Â k	 Â is	 Â not	 Â really	 Â small,	 Â 50	 Â buckets	 Â will	 Â 
be	 Â enough,	 Â thus	 Â fitting	 Â into	 Â the	 Â memory.	 Â 
This	 Â means	 Â the	 Â contribution	 Â of	 Â k	 Â is	 Â a	 Â 
factor	 Â that	 Â needs	 Â to	 Â be	 Â considered.	 Â When	 Â 
the	 Â bucket	 Â is	 Â full,	 Â write	 Â out	 Â to	 Â disk,	 Â 
avoiding	 Â continuously	 Â write	 Â in	 Â and	 Â out.	 Â 	 Â 
Join	 Â with	 Â U	 Â by	 Â reading	 Â in	 Â and	 Â writing	 Â out	 Â 
again.	 Â So	 Â here	 Â k	 Â must	 Â be	 Â small	 Â than	 Â 
memory	 Â which	 Â is	 Â k/50	 Â <=	 Â 100.(100	 Â is	 Â the	 Â 
estimate	 Â of	 Â memory)	 Â 
â€¢ Continuing:
â€¢ If	 Â k	 Â >	 Â 5000	 Â then	 Â materialize	 Â instead	 Â of	 Â pipeline
â€¢ 2	 Â partitioned	 Â hash-Â­â€joins
â€¢ Cost	 Â 3B(R)	 Â +	 Â 3B(S)	 Â +	 Â 4k	 Â +	 Â 3B(U)	 Â =	 Â 75000	 Â +	 Â 4k
Example
Query	 Â Optimization	 Â (53	 Â of	 Â 64)
R(w,x)
5,000 blocks
S(x,y)
10,000 blocks
U(y,z)
10,000 blocks
k blocks
Completing	 Â Physical	 Â Query	 Â Plan	 Â (12	 Â of	 Â 13) 	 Â 
If	 Â K	 Â is	 Â greater	 Â than	 Â 5000(	 Â k/50	 Â >	 Â 100),	 Â the	 Â 
cost	 Â must	 Â not	 Â neglect	 Â the	 Â component	 Â of	 Â 
K.	 Â Now	 Â K	 Â will	 Â not	 Â be	 Â fitted	 Â into	 Â the	 Â 
memory,	 Â we	 Â have	 Â to	 Â fully	 Â materialize	 Â and	 Â 
go	 Â back	 Â to	 Â the	 Â naÃ¯ve	 Â method.	 Â 
We	 Â always	 Â use	 Â hash	 Â join	 Â because	 Â it	 Â can	 Â be	 Â 
faster.	 Â 
â€¢ Summary:
â€¢ If	 Â k	 Â <=	 Â 50,	 Â  cost	 Â =	 Â 55,000
â€¢ If	 Â 50	 Â <	 Â k	 Â <=5000, cost	 Â =	 Â 75,000	 Â +	 Â 2k
â€¢ If	 Â k	 Â >	 Â 5000, cost	 Â =	 Â 75,000	 Â +	 Â 4k
Example
Query	 Â Optimization	 Â (54	 Â of	 Â 64)Completing	 Â Physical	 Â Query	 Â Plan	 Â (13	 Â of	 Â 13) 	 Â 
Given	 Â the	 Â summary	 Â of	 Â the	 Â k	 Â valueâ€™s	 Â 
corresponding	 Â cost.	 Â So	 Â next	 Â problem	 Â is	 Â 
how	 Â to	 Â calculate	 Â the	 Â value	 Â of	 Â K?	 Â Not	 Â run	 Â a	 Â 
join	 Â directly:	 Â too	 Â expensive	 Â and	 Â lose	 Â the	 Â 
initial	 Â purpose.	 Â 
Estimating	 Â Sizes
Query Â Optimization Â (55 Â of Â 64)Estimating Â Sizes Â (0 Â of Â 9) 	 Â 
Estimating	 Â the	 Â size	 Â of	 Â the	 Â intermediate	 Â 
results	 Â of	 Â different	 Â operators	 Â in	 Â practical	 Â 
process	 Â 
Reason:	 Â need	 Â size	 Â to	 Â implement	 Â different	 Â 
methods	 Â to	 Â minimize	 Â the	 Â cost.	 Â 
â€¢ Need	 Â size	 Â in	 Â order	 Â to	 Â estimate	 Â cost
â€¢ Example:
â€¢ Cost	 Â of	 Â partitioned	 Â hash-Â­â€join	 Â ğ¸1 â‹ˆ ğ¸2 Â is	 Â 3ğµ(ğ¸1) Â + Â 3ğµ(ğ¸2)
â€¢ ğµ(ğ¸1)  Â =  Â ğ‘‡(ğ¸1)/ Â ğ‘ğ‘™ğ‘œğ‘ğ‘˜ Â ğ‘ ğ‘–ğ‘§ğ‘’
â€¢ ğµ(ğ¸2)  Â =  Â ğ‘‡(ğ¸2)/ Â ğ‘ğ‘™ğ‘œğ‘ğ‘˜ Â ğ‘ ğ‘–ğ‘§ğ‘’
â€¢ So,	 Â we	 Â need	 Â to	 Â estimate	 Â ğ‘‡(ğ¸1), ğ‘‡(ğ¸2)
Estimating	 Â Sizes
Query	 Â Optimization	 Â (56	 Â of	 Â 64)Estimating	 Â Sizes	 Â (1	 Â of	 Â 9) 	 Â 
	 Â 
â€¢ Estimating	 Â the	 Â size	 Â of	 Â a	 Â projection
â€¢ Easy:	 Â ğ‘‡(ğœ‹$(ğ‘…))  Â =  Â ğ‘‡(ğ‘…)
â€¢ A projection	 Â doesnâ€™t	 Â eliminate	 Â duplicates
Estimating	 Â Sizes
Query	 Â Optimization	 Â (57	 Â of	 Â 64)Estimating	 Â Sizes	 Â (2	 Â of	 Â 9) 	 Â 
The	 Â size	 Â of	 Â projection	 Â is	 Â easy,	 Â it	 Â stays	 Â the	 Â 
same	 Â as	 Â projection	 Â does	 Â not	 Â reduce	 Â the	 Â 
size	 Â of	 Â the	 Â relation.	 Â 
â€¢ Estimating	 Â the	 Â size	 Â of	 Â a	 Â selection
â€¢ ğ‘† Â  = ğœ%&'(ğ‘…)
â€¢ T(S)	 Â can	 Â be	 Â anything	 Â from	 Â 0	 Â to	 Â ğ‘‡(ğ‘…) Â â€“  Â ğ‘‰(ğ‘…, ğ´)  Â +  Â 1
â€¢ Mean	 Â value:	 Â ğ‘‡(ğ‘†)  Â =  Â ğ‘‡(ğ‘…)/ğ‘‰(ğ‘…, ğ´)
â€¢ ğ‘† Â  = ğœ%3'(ğ‘…)
â€¢ T(S)	 Â can	 Â be	 Â anything	 Â from	 Â 0	 Â to	 Â ğ‘‡(ğ‘…)
â€¢ Heuristics:	 Â ğ‘‡(ğ‘†)  Â =  Â ğ‘‡(ğ‘…)/3
Estimating	 Â Sizes
Query	 Â Optimization	 Â (58	 Â of	 Â 64)Estimating	 Â Sizes	 Â (3	 Â of	 Â 9) 	 Â 
A=c	 Â example:	 Â suppose	 Â there	 Â are	 Â 1000	 Â 
students,	 Â we	 Â want	 Â to	 Â select	 Â the	 Â students	 Â 
whose	 Â department	 Â is	 Â CS.	 Â There	 Â are	 Â 5	 Â 
departments.	 Â Each	 Â department	 Â is	 Â uniform	 Â 
So	 Â V(R,A)=5,	 Â T(R)=1000,	 Â T(S)=1000/5=200	 Â 
(just	 Â approximation)	 Â 
A<c	 Â example:	 Â 	 Â 
Select	 Â student	 Â with	 Â GPA>3.5:	 Â 1000/3	 Â 
Select	 Â student	 Â with	 Â GPA>2.5:	 Â 1000/3	 Â 
Select	 Â student	 Â with	 Â GPA>1.0:	 Â 1000/3	 Â 
	 Â 
â€¢ Estimating	 Â the	 Â size	 Â of	 Â a	 Â natural	 Â join,	 Â ğ‘… â‹ˆ# ğ‘† Â 
â€¢ When	 Â the	 Â set	 Â of	 Â A	 Â values	 Â are	 Â disjoint,	 Â then	 Â 
â€¢ ğ‘‡(ğ‘… â‹ˆ# ğ‘†)  Â =  Â 0
â€¢ When	 Â A	 Â is	 Â a	 Â key	 Â in	 Â S	 Â and	 Â a	 Â foreign	 Â key	 Â in	 Â R,	 Â then	 Â ğ‘‡(ğ‘… â‹ˆ# ğ‘†)  Â = ğ‘‡(ğ‘…)
â€¢ When	 Â A	 Â has	 Â a	 Â unique	 Â value,	 Â the	 Â same	 Â in	 Â R	 Â and	 Â S,	 Â 
then	 Â ğ‘‡ ğ‘… â‹ˆ# ğ‘† = min ğ‘‡ ğ‘… , ğ‘‡ ğ‘† .
Estimating	 Â Sizes
Query	 Â Optimization	 Â (59	 Â of	 Â 64)Estimating	 Â Sizes	 Â (4	 Â of	 Â 9) 	 Â 
Key	 Â and	 Â foreign	 Â key	 Â example:	 Â 
Natural	 Â join	 Â on	 Â Sells	 Â and	 Â Beers	 Â with	 Â 
attribute	 Â beer,	 Â T(S)	 Â =	 Â 1000,	 Â T(B)=20,	 Â then	 Â 
T(S	 Â join	 Â B)=1000,	 Â since	 Â beer	 Â is	 Â a	 Â key	 Â in	 Â 
Beers	 Â and	 Â a	 Â foreign	 Â key	 Â in	 Â Sells.	 Â 
	 Â Unique	 Â value:	 Â 	 Â 
Natural	 Â join	 Â on	 Â Students	 Â and	 Â TAs	 Â with	 Â the	 Â 
same	 Â unique	 Â value	 Â Netid.	 Â The	 Â set	 Â of	 Â netid	 Â 
in	 Â TAs	 Â will	 Â be	 Â a	 Â subset	 Â of	 Â the	 Â set	 Â of	 Â netid	 Â 
on	 Â students.	 Â So	 Â T(Students	 Â join	 Â 
TAs)=T(TAs)	 Â 
â€¢ Assumptions:
â€¢ Containment	 Â of	 Â values:	 Â if	 Â ğ‘‰(ğ‘…, ğ´)  Â <= Â ğ‘‰(ğ‘†, ğ´), Â then	 Â the	 Â set	 Â of	 Â R.A	 Â values	 Â is	 Â included	 Â in	 Â 
the	 Â set	 Â of	 Â S.A	 Â values
â€¢ Indeed	 Â holds	 Â when	 Â A	 Â is	 Â a	 Â foreign	 Â key	 Â in	 Â R,	 Â and	 Â a	 Â key	 Â in	 Â S
â€¢ Preservation	 Â of	 Â values:	 Â for	 Â any	 Â other	 Â attribute	 Â ğµ,	 Â 	 Â 
â€¢ ğ‘‰ ğ‘… â‹ˆ- ğ‘†, ğµ = ğ‘‰ ğ‘…, ğµ or	 Â ğ‘‰ ğ‘†, ğµ .
Estimating	 Â Sizes
Query	 Â Optimization	 Â (60	 Â of	 Â 64)Estimating	 Â Sizes	 Â (5	 Â of	 Â 9) 	 Â 
Two	 Â assumptions:	 Â 	 Â 
First:	 Â Smaller	 Â set	 Â is	 Â included	 Â in	 Â the	 Â bigger	 Â 
set.	 Â 	 Â 
Second:	 Â Give	 Â a	 Â sells/beer	 Â example	 Â here.	 Â 	 Â 	 Â 
Sells	 Â join	 Â beer	 Â on	 Â beer(or	 Â name)	 Â and	 Â 
other	 Â attributes	 Â should	 Â be	 Â preserved,	 Â like	 Â 
bar	 Â name	 Â will	 Â be	 Â preserved	 Â in	 Â the	 Â result.	 Â 
â€¢ Assume	 Â ğ‘‰(ğ‘…, ğ´)  Â <=  Â ğ‘‰(ğ‘†, ğ´)
â€¢ Then	 Â each	 Â tuple	 Â ğ‘¡ in	 Â ğ‘… joins	 Â some	 Â tuple(s)	 Â in	 Â ğ‘†
â€¢ How	 Â many?
â€¢ On	 Â average	 Â ğ‘†/ğ‘‰(ğ‘†, ğ´)
â€¢ It	 Â will	 Â contribute	 Â ğ‘†/ğ‘‰(ğ‘†, ğ´) tuples	 Â in	 Â ğ‘… â‹ˆ. ğ‘†
â€¢ Hence	 Â ğ‘‡ ğ‘… â‹ˆ. ğ‘† = ğ‘‡ ğ‘… ğ‘‡(ğ‘†)/ğ‘‰(ğ‘†, ğ´)
â€¢ In	 Â general:	 Â 
â€¢ ğ‘‡ ğ‘… â‹ˆ. ğ‘† = ğ‘‡ ğ‘… ğ‘‡(ğ‘†)/max(ğ‘‰ ğ‘…, ğ´ , ğ‘‰ ğ‘†, ğ´ )
Estimating	 Â Sizes
Query	 Â Optimization	 Â (61	 Â of	 Â 64)Estimating	 Â Sizes	 Â (6	 Â of	 Â 9) 	 Â 
Given	 Â an	 Â example	 Â of	 Â student/TA	 Â table	 Â join	 Â 
on	 Â netId.	 Â 
Suppose	 Â A	 Â in	 Â R	 Â are	 Â 250	 Â netIds	 Â in	 Â TA	 Â table.	 Â 
And	 Â assume	 Â R	 Â is	 Â a	 Â subset	 Â of	 Â S.	 Â So	 Â T(s)	 Â /	 Â 
V(S,	 Â A)	 Â number	 Â of	 Â tuples	 Â will	 Â be	 Â joined	 Â in	 Â 
S.	 Â 
And	 Â in	 Â general,	 Â we	 Â chose	 Â the	 Â bigger	 Â set	 Â of	 Â 
values	 Â as	 Â the	 Â divider.	 Â 	 Â 
Same	 Â situation	 Â in	 Â sells:	 Â T(sells)/V(sells,	 Â b)	 Â 
â€¢ Example:
â€¢ ğ‘‡(ğ‘…)  Â =  Â 10000, ğ‘‡(ğ‘†)  Â =  Â 20000
â€¢ ğ‘‰(ğ‘…, ğ´)  Â =  Â 100, ğ‘‰(ğ‘†, ğ´)  Â =  Â 200
â€¢ How	 Â large	 Â is	 Â ğ‘… â‹ˆ/ ğ‘† ?
â€¢ Answer:	 Â 
â€¢ ğ‘‡(ğ‘… â‹ˆ/ ğ‘†) =  Â 10000 Â  âˆ—  Â 20000/200 Â  =  Â 1ğ‘€
Estimating	 Â Sizes
Query	 Â Optimization	 Â (62	 Â of	 Â 64)Estimating	 Â Sizes	 Â (7	 Â of	 Â 9) 	 Â 
An	 Â example	 Â about	 Â estimating	 Â the	 Â size	 Â of	 Â 
join	 Â using	 Â previous	 Â formula	 Â and	 Â rules.	 Â 
â€¢ Joins	 Â on	 Â more	 Â than	 Â one	 Â attribute:
â€¢ ğ‘‡ ğ‘… â‹ˆ$ ğ‘† = ' ( ' )*+, - (,$ ,- ),$ â‹…*+, Â (- (,2 ,- ),2 )
Estimating	 Â Sizes
Query	 Â Optimization	 Â (63	 Â of	 Â 64)Estimating	 Â Sizes	 Â (8	 Â of	 Â 9) 	 Â 
Impractical Â example, Â just Â take Â it Â as Â another Â view. Â  Â 
(The	 Â slide	 Â is	 Â wrong,	 Â should	 Â be	 Â T(R	 Â  A,B	 Â s)).	 Â 
â€¢ Statistics	 Â on	 Â data	 Â maintained	 Â by	 Â the	 Â RDBMS
â€¢ Makes	 Â size	 Â estimation	 Â much	 Â more	 Â accurate	 Â (hence,	 Â 
cost	 Â estimations	 Â are	 Â more	 Â accurate)
â€¢ Ranks(rankName,	 Â salary)
â€¢ Estimate	 Â the	 Â size	 Â of	 Â ğ¸ğ‘šğ‘ğ‘™ğ‘œğ‘¦ğ‘’ğ‘’ Â  â‹ˆ*+,+-. ğ‘…ğ‘ğ‘›ğ‘˜ğ‘ 
More	 Â statistics	 Â helps:	 Â E.g.,	 Â Histograms
Query	 Â Optimization	 Â (64	 Â of	 Â 64)
Employee 0..20k 20k..40k 40k..60k 60k..80k 80k..100k > 100k
200 800 5000 12000 6500 500
Ranks 0..20k 20k..40k 40k..60k 60k..80k 80k..100k > 100k
8 20 40 80 100 2
Estimating	 Â Sizes	 Â (9	 Â of	 Â 9) 	 Â 
Statistics	 Â on	 Â data	 Â can	 Â make	 Â the	 Â estimate	 Â 
more	 Â accurate.	 Â 	 Â 
Having	 Â range	 Â size	 Â will	 Â make	 Â things	 Â easier.	 Â 
Example:	 Â T(Employee	 Â join	 Â Ranks	 Â on	 Â 
salary)=	 Â T(E1	 Â joins	 Â R1)	 Â 
A	 Â TED	 Â talk	 Â Meet	 Â the	 Â SixthSense	 Â 
interaction	 Â was	 Â presented!	 Â 
	 Â 
	 Â 
