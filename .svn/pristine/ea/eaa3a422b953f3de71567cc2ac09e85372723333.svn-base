Kevin C. Chang
Query Processing
Database Systems
• Logical/physical operators
•Cost parameters and sorting 
•One‐pass algorithms 
• Nested‐loop join 
•Two‐pass algorithms
• Sort‐merge join
• Hash‐based join
• Index‐based algorithms
• Index‐based join
Concepts You Will Learn
Indexing (1 of 66)
The Big Picture: Where We Are
Indexing (2 of 66)
Data Access
Data Modeling
Data/Query Processing
Data Acquisition
Relational NonRelational
S
t
r
u
c
t
u
r
e
d
S
e
m
i
S
t
r
u
c
t
u
r
e
d
Transaction Management
N
o
S
Q
L
 
D
a
t
a
b
a
s
e
s
X
M
L
 
D
a
t
a
b
a
s
e
s
U
n
t
r
u
c
t
u
r
e
d
Relational Databases
• SQL
• Relational Algebra
• Query Optimization
• Query Execution
• Indexing
• Concurrency Control
• Logging Recovery
Database Systems Toolkits
M
a
p
 
R
e
d
u
c
e
(
P
a
r
a
l
l
e
l
)
S
t
o
r
m
 
(
S
t
r
e
a
m
)
Information Extraction
ER  Relational Model
Query Language
Why Do We Learn This?
4
Overview
5
Query Execution
6
Query compiler
Execution engine
Index/record mgr.
Buffer manager
Storage manager
storage
User/
Application
Query
or update
Query execution
plan
Record, index
requests
Page 
commands
Read/write
pages
• Logical operators
•what they do
• e.g., union, selection, project, join, grouping
•Physical operators
• how they do it
• e.g., nested loop join, sort‐merge join, hash join, index 
join
Logical v.s. Physical Operators
7
Query Execution Plans
8
Purchase Person
Buyer=name
City=‘urbana’ phone>’5430000’
buyer
(Simple Nested Loops)
SELECT S.sname
FROM     Purchase P, Person Q
WHERE  P.buyer=Q.name AND
Q.city=‘urbana’ AND
Q.phone > ‘5430000’ 

Query Plan:
• logical tree
• implementation   
choice at every node
• scheduling of 
operations.
(Table scan) (Index scan)
Some operators are from relational
algebra, and others (e.g., scan, group) are not.
The iterator model.
•Each operation is implemented by 3 functions:
• Open: sets up the data structures and performs 
initializations
• GetNext: returns the the next tuple of the result.
• Close: ends the operations. Cleans up the data structures.
•Enables pipelining!
How do We Combine Operations?
9
•Cost parameters  
•M = number of blocks that fit in main memory
• B(R) = number of blocks holding R
• T(R) = number of tuples in R
• V(R,a) = number of distinct values of the attribute a
•Estimating the cost:
• Important in optimization (next lecture)
• Compute I/O cost only
•We compute the cost to read the tables 
•We don’t compute the cost to write the result (because 
pipelining)
Cost Parameters
10
•Two pass multi‐way merge sort
•Step 1:
• Read M blocks at a time, sort, write
• Result: have runs of length M on disk
•Step 2:
•Merge M‐1 at a time, write to disk
• Result: have runs of length M(M‐1)M2
•Cost: 3B(R),  Assumption: B(R) M2
Sorting
11
•The table is clustered (I.e. blocks consists only of 
records from this table):
• Table‐scan: if we know where the blocks are
• Index scan: if we have index to find the blocks
•The table is unclustered (e.g. its records are placed 
on blocks with other tables)
•May need one read for each record
Scanning Tables
12
•Clustered relation:
• Table scan:  B(R); to sort: 3B(R)
• Index scan:  B(R); to sort: B(R) or 3B(R)
•Unclustered relation
• T(R); to sort: T(R) + 2B(R)
Cost of the Scan Operator
13
One‐Pass Algorithms
14
Selection (R), projection (R)
•Both are tuple‐at‐a‐Time algorithms
•Cost: B(R)
One‐pass Algorithms
15
Input buffer Output bufferUnary
operator
Duplicate elimination (R)
•Need to keep a dictionary in memory:
• balanced search tree
• hash table
• etc
•Cost: B(R)
•Assumption: B((R)) <= M
One‐pass Algorithms
16
Grouping: city, sum(price) (R)
•Need to keep a dictionary in memory
•Also store the sum(price) for each city
•Cost: B(R)
•Assumption: number of cities fits in memory
One‐pass Algorithms
17
Binary operations: R ∩ S, R U S, R – S
•Assumption: min(B(R), B(S)) <= M
•Scan one table first, then the next, eliminate 
duplicates
•Cost: B(R)+B(S)
One‐pass Algorithms
18
•Tuple‐based nested loop 
•R=outer relation, S=inner relation
for each tuple r in R do
for each tuple s in S do
if r and s join then output (r,s)
•Cost: T(R) T(S),  sometimes T(R) B(S)
Nested Loop Joins
19
•Block‐based Nested Loop Join
for each (M‐1) blocks bs of S do
for each block br of R do
for each tuple s in bs do
for each tuple r in br do
if r and s join then output(r,s)
Nested Loop Joins
20
Nested Loop Joins
21
. . .
. . .
R & S
Blocks of S
(k < M-1 pages)
Input buffer for R Output buffer
. . .
Join Result
•Block‐based Nested Loop Join
•Cost:
• Read S once: cost B(S)
• Outer loop runs B(S)/(M‐1) times, and each time need to 
read R: costs B(S)B(R)/(M‐1)
• Total cost:  B(S)  +  B(S)B(R)/(M‐1)
•Notice: it is better to iterate over the smaller 
relation first– i.e., S smaller
Nested Loop Joins
22
Two‐Pass Algorithms
23
Two pass algorithms
24
Duplicate elimination (R)
•Simple idea: like sorting, but include no duplicates
•Step 1: sort runs of size M, write
• Cost: 2B(R)
•Step 2: merge M‐1 runs, 
but include each tuple only once
• Cost: B(R)
•Total cost: 3B(R), Assumption: B(R) <= M2
Two‐Pass Algorithms Based on Sorting
25
•Selection?
•Projection?
•Set operations?
• Join?
•Duplicate elimination?
•Grouping?
Q: What can sorting help? And, how?
26
Grouping: city, sum(price) (R)
•Same as before: sort, then compute the sum(price) 
for each group
•As before: compute sum(price) during the merge 
phase.
•Total cost: 3B(R)
•Assumption: B(R) <= M2
Two‐Pass Algorithms Based on Sorting
27
Binary operations: R ∩ S, R U S, R – S
• Idea: sort R, sort S, then do the right thing
•A closer look:
• Step 1: split R into runs of size M, then split S into runs of 
size M.  Cost: 2B(R) + 2B(S)
• Step 2: merge all x runs from R; merge all y runs from S; 
ouput a tuple on a case by cases basis (x + y <= M)
•Total cost: 3B(R)+3B(S)
•Assumption: B(R)+B(S)<= M2
Two‐Pass Algorithms Based on Sorting
28
Join 
•Start by sorting both R and S on the join attribute:
• Cost: 4B(R)+4B(S)  (because need to write to disk)
•Read both relations in sorted order, match tuples
• Cost: B(R)+B(S)
•Difficulty: many tuples in R may match many in S
• If at least one set of tuples fits in M, we are OK
• Otherwise need nested loop, higher cost
•Total cost: 5B(R)+5B(S)
•Assumption: B(R) <= M2, B(S) <= M2
Sort‐Merge Join
29
•Pass 1?
•Pass 2?
Q: Why is sorting‐based “two” pass?
30
• Idea: partition a relation R into buckets, on disk
•Each bucket has size approx. B(R)/M
•Does each bucket fit in main memory ?
• Yes if B(R)/M <= M,   i.e. B(R) <= M2
Two Pass Algorithms Based on Hashing
31
M main memory buffers DiskDisk
Relation R
OUTPUT
2INPUT
1
hash
function
h M-1
Partitions
1
2
M-1
. . .
1
2
B(R)
•Selection?
•Projection?
•Set operations?
• Join?
•Duplicate elimination?
•Grouping?
Q: What can hashing help? And, how?
32
• Recall:  (R) duplicate elimination 
• Step 1. Partition R into buckets
• Step 2. Apply  to each bucket (may read in main memory)
• Cost: 3B(R)
• Assumption:B(R) <= M2
Hash Based Algorithms for  
33
•Recall:  (R) grouping and aggregation
•Step 1. Partition R into buckets
•Step 2. Apply  to each bucket (may read in main 
memory)
•Cost: 3B(R)
•Assumption: B(R) <= M2
Hash Based Algorithms for  
34
•Simple version: main memory hash‐based join
• Scan S, build buckets in main memory
• Then scan R and join
•Requirement: min(B(R), B(S)) <= M
Hash‐based Join
35
•Step 1:
• Hash S into M buckets
• send all buckets to disk
•Step 2
• Hash R into M buckets
• Send all buckets to disk
•Step 3
• Join every pair of buckets
Partitioned Hash Join
36
• Partition both 
relations using hash fn
h:  R tuples in partition 
i will only match S 
tuples in partition i.
• Read in a partition of 
R, hash it using h2 (<> 
h!). Scan matching 
partition of S, search 
for matches.
Partitioned Hash‐Join
Partitions
of R & S
Input buffer
for Ri
Hash table for partition
Si ( < M-1 pages)
B main memory buffersDisk
Output 
buffer
Disk
Join Result
hash
fn
h2
h2
B main memory buffers DiskDisk
Original 
Relation OUTPUT
2INPUT
1
hash
function
h M-1
Partitions
1
2
M-1
. . .
37
•Cost: 3B(R) + 3B(S)
•Assumption: At least one full bucket of the smaller 
rel must fit in memory: min(B(R), B(S)) <= M2
Partitioned Hash Join
38
Index‐based Algorithms (Zero‐
Pass)
39
• In a clustered index all tuples with the same value 
of the key are clustered on as few blocks as 
possible.
Indexed Based Algorithms
40
a a a a a a a a a a       
•Selection on equality: a=v(R)
•Clustered index on a:  cost B(R)/V(R,a)
•Unclustered index on a: cost T(R)/V(R,a)
Index Based Selection
41
•Example: B(R) = 2000,  T(R) = 100,000, V(R, a) = 20, 
compute the cost of a=v(R)
•Cost of table scan:
• If R is clustered: B(R) = 2000 I/Os
• If R is unclustered: T(R) = 100,000 I/Os
•Cost of index based selection:
• If index is clustered: B(R)/V(R,a) = 100
• If index is unclustered: T(R)/V(R,a) = 5000
•Notice: when V(R,a) is small, then unclustered index 
is useless
Index Based Selection
42
ܴ	 ⋈ ܵ
• Assume S has an index on the join attribute
• Iterate over R, for each tuple fetch corresponding tuple(s) 
from S
• Assume R is clustered. Cost:
• If index is clustered:  B(R) + T(R)B(S)/V(S,a)
• If index is unclustered: B(R) + T(R)T(S)/V(S,a)
Index Based Join
43
•Assume both R and S have a sorted index (B+ tree) 
on the join attribute
•Then perform a merge join (called zig‐zag join)
•Cost: B(R) + B(S)
Index Based Join
44
