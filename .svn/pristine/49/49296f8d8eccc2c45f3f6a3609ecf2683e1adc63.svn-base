Kevin C. Chang
Query Processing
Database Systems
1
 
 
• Logical/physical operators
•Cost parameters and sorting 
•One-pass algorithms 
• Nested-loop join 
•Two-pass algorithms
• Sort-merge join
• Hash-based join
• Index-based algorithms
• Index-based join
Concepts You Will Learn
Indexing (1 of 66)Default Section (1 of 2)
 
An outline of what will be covered  
Logical/Physical Operators: more 
One-pass algorithms: more 
Two-pass algorithms: Similar to one-
pass but makes two passes over the 
data: the first to assign temp labels and 
record equivalences and the second to 
the temp label. 
Index-based algorithm: Didn’t get to it. 
 
 
The Big Picture: Where We Are
Indexing (2 of 66)
Data Access
Data Modeling
Data/Query Processing
Data Acquisition
Relational NonRelational
St
ru
ct
u
re
d
Se
m
iS
tr
u
ct
u
re
d
Transaction Management
N
o
SQ
L 
D
at
ab
as
e
s
X
M
L 
D
at
ab
as
e
s
U
n
tr
u
ct
u
re
d
Relational Databases
• SQL
• Relational Algebra
• Query Optimization
• Query Execution
• Indexing
• Concurrency Control
• Logging Recovery
Database Systems Toolkits
M
ap
 R
e
d
u
ce
(P
ar
al
le
l)
St
o
rm
 
(S
tr
e
am
)
Information Extraction
ER  Relational Model
Query Language
 
There are 2 dimensions to data.  
The first dimension - In red, we can see 
the format of the data in the world. This 
comes as structured and unstructured. 
The second dimension can be derived 
from the question: Is it relational or not? 
(Content in blue).  
The question thus far has been, given 
unstructured data, how do we get that 
into a structured database? 
As highlighted in the data, we can see the 
transition of the class from SQL to 
relational algebra, to XML and so forth. 
This is our exploration of Relational and 
Non-relational.  
Query Execution
4
Query compiler
Execution engine
Index/record mgr.
Buffer manager
Storage manager
storage
User/
Application
Query
or update
Query execution
plan
Record, index
requests
Page 
commands
Read/write
pages
 
The figure depicts a fine grain model of 
query execution. If we were to run a 
query, then we follow the path shown: 
An SQL command goes into a query 
complier. This will be processed by the 
execution engine, which runs on every 
operator. The index then comes in to give 
you the appropriate value (B-tree, Hash 
etc are the index types we are referring 
to). Following that, they will come into 
the buffer manager. This is the virtual 
manager where it is decided what will 
come to the memory (This is the pin index 
to the memory). And finally, it goes to the 
storage manager that gets us the final 
output.   
• Logical operators
• what they do
• e.g., union, selection, project, join, grouping
•Physical operators
• how they do it
• e.g., nested loop join, sort-merge join, hash join, index 
join
Logical v.s. Physical Operators
5
 
Query is simply a structure of “lego” 
operators, thus all queries boil down to 
operators. 
Logical operators: has input and output. 
Physical operator: defined by method 
Logical/Physical Operators: more info. 
 
 
Query Execution Plans
6
Purchase Person
Buyer=name
City=‘urbana’ phone>’5430000’
buyer
(Simple Nested Loops)
SELECT S.sname
FROM     Purchase P, Person Q
WHERE  P.buyer=Q.name AND
Q.city=‘urbana’ AND
Q.phone > ‘5430000’ 

Query Plan:
• logical tree
• implementation   
choice at every node
• scheduling of 
operations.
(Table scan) (Index scan)
Some operators are from relational
algebra, and others (e.g., scan, group) are not.
 
Given several building blocks, we get the 
alternative of having multiple ways of 
performing a task. This means that given 
a set of methods to perform a task, an 
optimal method may exist.  The diagram 
to the left shows a breakdown of the 
query listed.  
Through query optimization, we can 
generate a tree as shown.  
The iterator model.
•Each operation is implemented by 3 functions:
• Open: sets up the data structures and performs 
initializations
• GetNext: returns the the next tuple of the result.
• Close: ends the operations. Cleans up the data structures.
•Enables pipelining!
How do We Combine Operations?
7
 
The iterator model is a model that we can 
use to help the query optimizing process. 
The iterator model means that you as a 
programmer will follow 3 functions: 
Open, GetNext, and Close.  
The iterator model also enables 
pipelining. This is simply the process line 
of different stages where every stage 
(such as selection, join, etc) is a busy 
process in some tuple. This means that if 
we have a multi-core processor, then we 
are using all cores such that there is no 
waste in resources.  
•Cost parameters  
• M = number of blocks that fit in main memory
• B(R) = number of blocks holding R
• T(R) = number of tuples in R
• V(R,a) = number of distinct values of the attribute a
•Estimating the cost:
• Important in optimization (next lecture)
• Compute I/O cost only
• We compute the cost to read the tables 
• We don’t compute the cost to write the result (because 
pipelining)
Cost Parameters
8
 
Sellinger: The director of the IBM 
computer science division. Worked on the 
system R project and worked on the 
concept of cost based optimization for 
queries.  
Optimization fundamentally means 
searching for the best.  
The concept  
Since different query plans have different 
costs, Sellinger decided that this can be 
used to optimize the query. The 
parameters that are ideal for utilization 
for this are listed on the slide.  
•Two pass multi-way merge sort
•Step 1:
• Read M blocks at a time, sort, write
• Result: have runs of length M on disk
•Step 2:
• Merge M-1 at a time, write to disk
• Result: have runs of length M(M-1)M2
•Cost: 3B(R),  Assumption: B(R)  M2
Sorting
9
 
** This is different from the sorting 
algorithms we have learned in our data 
structures courses.  
For example:  
Suppose we want to sort R such that, 
memory to disk = 1000, B(R) = 20kb. 
First we read R. Memory can only hold 
1000 elements, so R will run 20 times 
(each time 1000 elements, 20k total). 
Merge after one at a time.  
We are assuming B(R) <= M2. If this is 
not satisfied, we will need more 
steps/iterations. That will make it more 
expensive. The cost is 3*B(R) if the 
assumption is qualified. 
.  
•The table is clustered (I.e. blocks consists only of 
records from this table):
• Table-scan: if we know where the blocks are
• Index scan: if we have index to find the blocks
•The table is unclustered (e.g. its records are placed 
on blocks with other tables)
• May need one read for each record
Scanning Tables
10
 
Tuples are clusters or unclustered.  
If table is clustered, we mean they are 
contiguous on disk. Thus, when reading, 
you spend B(R) time to read it. 
If tables are unclustered, it is possible 
that every record is placed in a different 
block. Worst case time spent reading it 
could be T(R). 
  
  
•Clustered relation:
• Table scan:  B(R); to sort: 3B(R)
• Index scan:  B(R); to sort: B(R) or 3B(R)
•Unclustered relation
• T(R); to sort: T(R) + 2B(R)
Cost of the Scan Operator
11
 
Professor didn’t really touch on this one… 
Selection (R), projection P(R)
•Both are tuple-at-a-Time algorithms
•Cost: B(R)
One-pass Algorithms
12
Input buffer Output bufferUnary
operator
 
One-pass algorithm 
A pass is a “phase” of processing. Imagine 
this as one pass through the data.  
At each pass, we have a unary operator, 
like a select or a projection that goes 
through the data and gives an output in 
the buffer. One tuple at a time is 
processed.  
Duplicate elimination d(R)
•Need to keep a dictionary in memory:
• balanced search tree
• hash table
• etc
•Cost: B(R)
•Assumption: B(d(R)) <= M
One-pass Algorithms
13
 
In the example of a duplicate elimination, 
we use a delta operator.  
The operator DISTINCT is a great example 
of a way to eliminate duplicates. With the 
query SELECT DISTINCT names FROM 
users, we get all the distinct user names.  
However, what this means is that we 
need to maintain a dictionary in memory.  
If we have a tuple coming in, then what 
we do is check it in the dictionary. If the 
tuple does not exist, then it is outputted 
and added to the data structure. 
However, if it is, then it means that it is a 
duplicate. We are basically building a 
dictionary in the main memory.  
Grouping: gcity, sum(price) (R)
•Need to keep a dictionary in memory
•Also store the sum(price) for each city
•Cost: B(R)
•Assumption: number of cities fits in memory
One-pass Algorithms
14
 
Furthermore, operators such as Grouping 
(union, etc) all follow this same use case.  
Binary operations: R ∩ S, R U S, R – S
•Assumption: min(B(R), B(S)) <= M
•Scan one table first, then the next, eliminate 
duplicates
•Cost: B(R)+B(S)
One-pass Algorithms
15
 
Self-explanatory 
•Tuple-based nested loop      
•R=outer relation, S=inner relation
for each tuple r in R do
for each tuple s in S do
if r and s join then output (r,s)
•Cost: T(R) T(S),  sometimes T(R) B(S)
Nested Loop Joins
16
 
Join processes are very expensive. So 
we get the question of how we can 
optimize this.  
For first tuple of R, loop through S; for 
second tuple of R, loop through S again, 
etc. Thus, nested loop. 
  
•Block-based Nested Loop Join
for each (M-1) blocks bs of S do
for each block br of R do
for each tuple s in bs do
for each tuple r in br do
if r and s join then output(r,s)
Nested Loop Joins
17
 
To be smarter, store S in memory (can 
store M-1 items, 1 reserved for R). Loop 
S through every tuple in R. Then store 
another M-1 items in S. Keep doing this 
until S is looped through.  
Total Cost: B(S) + B(R) X B(S)/M 
 
Nested Loop Joins
18
. . .
. . .
R & S
Blocks of S
(k < M-1 pages)
Input buffer for R Output buffer
. . .
Join Result
 
 
•Block-based Nested Loop Join
•Cost:
• Read S once: cost B(S)
• Outer loop runs B(S)/(M-1) times, and each time need to 
read R: costs B(S)B(R)/(M-1)
• Total cost:  B(S)  +  B(S)B(R)/(M-1)
•Notice: it is better to iterate over the smaller 
relation first– i.e., S smaller
Nested Loop Joins
19
 
 
Two pass algorithms
20
 
 
Duplicate elimination d(R)
•Simple idea: like sorting, but include no duplicates
•Step 1: sort runs of size M, write
• Cost: 2B(R)
•Step 2: merge M-1 runs, 
but include each tuple only once
• Cost: B(R)
•Total cost: 3B(R), Assumption: B(R) <= M2
Two-Pass Algorithms Based on Sorting
21
 
 
•Selection?
•Projection?
•Set operations?
• Join?
•Duplicate elimination?
•Grouping?
Q: What can sorting help? And, how?
22
 
 
Grouping: gcity, sum(price) (R)
•Same as before: sort, then compute the sum(price) 
for each group
•As before: compute sum(price) during the merge 
phase.
•Total cost: 3B(R)
•Assumption: B(R) <= M2
Two-Pass Algorithms Based on Sorting
23
 
 
Binary operations: R ∩ S, R U S, R – S
• Idea: sort R, sort S, then do the right thing
•A closer look:
• Step 1: split R into runs of size M, then split S into runs of 
size M.  Cost: 2B(R) + 2B(S)
• Step 2: merge all x runs from R; merge all y runs from S; 
ouput a tuple on a case by cases basis (x + y <= M)
•Total cost: 3B(R)+3B(S)
•Assumption: B(R)+B(S)<= M2
Two-Pass Algorithms Based on Sorting
24
 
 
Join    
•Start by sorting both R and S on the join attribute:
• Cost: 4B(R)+4B(S)  (because need to write to disk)
•Read both relations in sorted order, match tuples
• Cost: B(R)+B(S)
•Difficulty: many tuples in R may match many in S
• If at least one set of tuples fits in M, we are OK
• Otherwise need nested loop, higher cost
•Total cost: 5B(R)+5B(S)
•Assumption: B(R) <= M2, B(S) <= M2
Sort-Merge Join
25
 
 
•Pass 1?
•Pass 2?
Q: Why is sorting-based “two” pass?
26
 
 
• Idea: partition a relation R into buckets, on disk
•Each bucket has size approx. B(R)/M
•Does each bucket fit in main memory ?
• Yes if B(R)/M <= M,   i.e. B(R) <= M2
Two Pass Algorithms Based on Hashing
27
M main memory buffers DiskDisk
Relation R
OUTPUT
2INPUT
1
hash
function
h M-1
Partitions
1
2
M-1
. . .
1
2
B(R)
 
 
•Selection?
•Projection?
•Set operations?
• Join?
•Duplicate elimination?
•Grouping?
Q: What can hashing help? And, how?
28
 
 
• Recall:  d(R) = duplicate elimination 
• Step 1. Partition R into buckets
• Step 2. Apply d to each bucket (may read in main memory)
• Cost: 3B(R)
• Assumption:B(R) <= M2
Hash Based Algorithms for  d
29
 
 
•Recall:  g(R) = grouping and aggregation
•Step 1. Partition R into buckets
•Step 2. Apply g to each bucket (may read in main 
memory)
•Cost: 3B(R)
•Assumption: B(R) <= M2
Hash Based Algorithms for  g
30
 
 
   
•Simple version: main memory hash-based join
• Scan S, build buckets in main memory
• Then scan R and join
•Requirement: min(B(R), B(S)) <= M
Hash-based Join
31
 
 
   
•Step 1:
• Hash S into M buckets
• send all buckets to disk
•Step 2
• Hash R into M buckets
• Send all buckets to disk
•Step 3
• Join every pair of buckets
Partitioned Hash Join
32
 
 
• Partition both 
relations using hash fn
h:  R tuples in partition 
i will only match S 
tuples in partition i.
• Read in a partition of 
R, hash it using h2 (<> 
h!). Scan matching 
partition of S, search 
for matches.
Partitioned Hash-Join
Partitions
of R & S
Input buffer
for Ri
Hash table for partition
Si ( < M-1 pages)
B main memory buffersDisk
Output 
buffer
Disk
Join Result
hash
fn
h2
h2
B main memory buffers DiskDisk
Original 
Relation OUTPUT
2INPUT
1
hash
function
h M-1
Partitions
1
2
M-1
. . .
 
 
•Cost: 3B(R) + 3B(S)
•Assumption: At least one full bucket of the smaller 
rel must fit in memory: min(B(R), B(S)) <= M2
Partitioned Hash Join
34
 
 
• In a clustered index all tuples with the same value 
of the key are clustered on as few blocks as 
possible.
Indexed Based Algorithms
35
a a a a a a a a a a       
 
 
•Selection on equality: a=v(R)
•Clustered index on a:  cost B(R)/V(R,a)
•Unclustered index on a: cost T(R)/V(R,a)
Index Based Selection
36
 
 
•Example: B(R) = 2000,  T(R) = 100,000, V(R, a) = 20, 
compute the cost of a=v(R)
•Cost of table scan:
• If R is clustered: B(R) = 2000 I/Os
• If R is unclustered: T(R) = 100,000 I/Os
•Cost of index based selection:
• If index is clustered: B(R)/V(R,a) = 100
• If index is unclustered: T(R)/V(R,a) = 5000
•Notice: when V(R,a) is small, then unclustered index 
is useless
Index Based Selection
37
 
 
    
• Assume S has an index on the join attribute
• Iterate over R, for each tuple fetch corresponding tuple(s) 
from S
• Assume R is clustered. Cost:
• If index is clustered:  B(R) + T(R)B(S)/V(S,a)
• If index is unclustered: B(R) + T(R)T(S)/V(S,a)
Index Based Join
38
 
 
•Assume both R and S have a sorted index (B+ tree) 
on the join attribute
•Then perform a merge join (called zig-zag join)
•Cost: B(R) + B(S)
Index Based Join
39
 
 
 
