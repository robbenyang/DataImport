Information	  Extraction
Vincent	  Zheng
	  
How	  do	  we	  get	  information	  in	  the	  first	  
place?	  
Where	  the	  data	  come	  from?	  
We	  need	  to	  populate	  the	  database.	  
The	  Big	  Picture:	  Where	  We	  Are
Data	  Access
Data	  Modeling
Data/Query	  Processing
Data	  Acquisition
Relational NonRelational
St
ru
ct
ur
ed
Se
m
iS
tr
uc
tu
re
d
Transaction	  Management
N
oS
Q
L	  
D
at
ab
as
es
XM
L	  
D
at
ab
as
es
U
nt
ru
ct
ur
ed
Relational	  Databases
• SQL
• Relational	  Algebra
• Query	  Optimization
• Query	  Execution
• Indexing
• Concurrency	  Control
• Logging	  Recovery
Database	  Systems Toolkits
M
ap
	  R
ed
uc
e
(P
ar
al
le
l)
St
or
m
	  
(S
tr
ea
m
)
Information	  Extraction
ER	  à Relational	  Model
Query	  Language
Default	  Section	  (1	  of	  2) Information	  Extraction	  (1	  of	  33)
	  
General	  Idea	  and	  Definition	  
Information	  Extraction:	  
The	  task	  of	  automatically	  extracting	  
structured	  information	  
from	  unstructured	  and/or	  semi-­‐
structured	  machine-­‐readable	  documents.	  
http://en.wikipedia.org/wiki/Information
_extraction	  
Concepts	  You	  Will	  Learn
• Different	  scenarios	  to	  populate	  DB
• Information	  Extraction	  (IE)
– Named	  Entity	  Recognition	  (NER)
• Different	  methods	  for	  IE	  with	  unstructured	  data
– Hard-­‐coded	  methods
– Learning-­‐based	  methods
• Logistic	  regression
• Conditional	  Random	  Fields	  (CRF)
Default	  Section	  (2	  of	  2) Information	  Extraction	  (1	  of	  31)
	  
The	  Most	  Important	  Thing	  You	  Should	  
Know	  
The	  methods	  for	  IE	  with	  unstructured	  
data:	  Hard-­‐coded,	  learning-­‐based	  
methods.	  
WHY	  DO	  WE	  LEARN	  THIS?
Why  Do  We  Learn  This?  (0  of  4) 4
	  
	  
You	  guys	  are	  doing	  a	  lot	  of	  interesting	  
DB-­‐supported	  projects
Why	  Do	  We	  Learn	  This?	  (1	  of	  4) 5
Image	  from	  http://godatabase.net/tag/database-­‐applications
How	  do	  you	  populate	  this	  DB?
	  
Where	  do	  we	  get	  data?	  
1.	  Edited/added	  by	  users	  
2.	  Crawl	  from	  the	  website	  	  
	  
Various	  Ways	  to	  Populate	  DB
• Someone	  edits	  it • Crawl	  from	  the	  Web
Why	  Do	  We	  Learn	  This?	  (2	  of	  4) 6
Image	  from	  http://www.joelonsoftware.com/
Joel	  is	  now	  23	  years	  old,	  
male,	  …
Micah	  is	  39,	  male	  ..
	  
Where	  do	  we	  get	  data?	  
1.	  Edited	  it	  by	  someone,	  such	  as	  users	  
(predetermined	  data)	  
=>	  Manually,	  tedious	  and	  prone	  to	  human	  
error	  
2.	  Crawl	  from	  the	  website	  
=>	  There	  are	  some	  irregularities	  in	  web	  
crawling	  	  
	  Ex:	  Get	  prices	  of	  books	  from	  Amazon.	  
Information	  Extraction	  As	  Data	  Acquisition
Why	  Do	  We	  Learn	  This?	  (3	  of	  4) 7
Joel	  is	  now	  23	  years	  old,	  
male,	  …
Micah	  is	  39,	  male	  ..
Joel	  is	  now	  23	  years	  old,	  
male,	  …
Micah	  is	  39,	  male	  ..
Joel	  is	  now	  23	  years	  old,	  
male,	  …
Micah	  is	  39,	  male	  ..
Joel	  is	  now	  23	  years	  old,	  
male,	  …
Micah	  is	  39,	  male	  ..
Image	  from	  www.homozygositymapper.org
Unstructured	  source:	  
e.g.,	  free	  text
Structured/Semi-­‐structured	  source:	  
e.g.,	  Web	  pages	  from	  a	  single	  site
	  
Goals	  is	  to	  get	  information	  from	  
1.Unstructured	  source	  (free	  text)	  
Unstructured Data (or unstructured 
information) refers to information that 
either does not have a pre-defined data 
model or is not organized in a pre-defined 
manner.  
http://en.wikipedia.org/wiki/Information
_extraction	  
	  2.Structured/	  semi-­‐structured	  source	  
(SQL,	  XML,	  Java	  Script)	  
Overview
• Focus	  of	  this	  lecture
– IE	  from	  unstructured	  free	  text
– Named	  Entity	  Recognition	  as	  an	  example
• Focus	  of	  next	  lecture
– IE	  from	  structured/semi-­‐structured	  Web	  pages
Why	  Do	  We	  Learn	  This?	  (4	  of	  4) 8
	  
There	  will	  be	  two	  lectures:	  one	  before	  
and	  one	  after	  Thanksgiving	  break.	  
This	  lecture	  will	  focus	  on	  unstructured	  	  
source	  (free	  text):	  
Illustrated	  by	  a	  Named	  Entity	  	  Recognition	  
example	  
	  
NER	  EXAMPLE
NER  Example  (0  of  7) 9
	  
Named	  Entity	  Recognition	  Example	  
Application
• Suppose	  you	  want	  to	  populate	  a	  DB	  about	  IT	  
company	  executives	  for	  techcrunch
– Given	  set	  of	  IT	  news	  Web	  pages
NER	  Example	  (1	  of	  7) 10
NAME      TITLE   ORGANIZATION
Bill Gates CEO Microsoft
Bill Veghte VP Microsoft
Richard Stallman founder Free Soft..
October	  14,	  2002,	  4:00	  a.m.	  PT
For	  years,	  Microsoft	  Corporation CEO Bill	  Gates railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  
software	  with	  Orwellian	  fervor,	  denouncing	  its	  
communal	  licensing	  as	  a	  "cancer"	  that	  stifled	  
technological	  innovation.
Today,	  Microsoft claims	  to	  "love"	  the	  open-­‐source	  
concept,	  by	  which	  software	  code	  is	  made	  public	  to	  
encourage	  improvement	  and	  development	  by	  outside
October	  14,	  2002,	  4:00	  a.m.	  PT
For	  years,	  Microsoft	  Corporation CEO Bill	  Gates railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  
software	  with	  Orwellian	  fervor,	  denouncing	  its	  
communal	  licensing	  as	  a	  "cancer"	  that	  stifled	  
technological	  innovation.
Today,	  Microsoft claims	  to	  "love"	  the	  open-­‐source	  
concept,	  by	  which	  software	  code	  is	   ade	  public	  to	  
encourage	  improvement	  and	  development	  by	  outside
October	  14,	  2002,	  4:00	  a.m.	  PT
For	  years,	  Microsoft	  Corporation CEO Bill	  Gates railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  
software	  with	  Orwellian	  fervor,	  denouncing	  its	  
communal	  licensing	  as	  a	  "cancer"	  that	  stifled	  
technological	  innovation.
Today,	  Microsoft claims	  to	  "love"	  the	  open-­‐source	  
concept,	  by	  which	  software	  code	  is	   ade	  public	  to	  
encourage	  improvement	  and	  development	  by	  outside
October	  14,	  2002,	  4:00	  a.m.	  PT
For	  years,	  Microsoft	  Corporation CEO Bill	  Gates railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  
software	  with	  Orwellian	  fervor,	  denouncing	  its	  
communal	  licensing	  as	  a	  "cancer"	  that	  stifled	  
technological	  innovation.
Today,	  Microsoft claims	  to	  "love"	  the	  open-­‐source	  
concept,	  by	  which	  software	  code	  is	   ade	  public	  to	  
encourage	  improvement	  and	  development	  by	  outside
	  
Given	  a	  source:	  A	  set	  of	  IT	  news	  Web	  
pages:	  Extract	  certain	  fields	  of	  
information	  out	  of	  the	  free	  text	  
Used	  Microsoft	  as	  an	  example:	  
information	  extract	  from	  the	  text	  
o Microsoft	  :	  Organization	  
o CEO:	  Relation	  
o Person:	  Bill	  Gates	  
	  
IE	  from	  Unstructured	  Free	  Text
Information	  Extraction	  =
segmentation	  +	  classification
As	  a	  family
of	  techniques:
October	  14,	  2002,	  4:00	  a.m.	  PT
For	  years,	  Microsoft	  Corporation CEO Bill	  Gates railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  
software	  with	  Orwellian	  fervor,	  denouncing	  its	  
communal	  licensing	  as	  a	  "cancer"	  that	  stifled	  
technological	  innovation.
Today,	  Microsoft claims	  to	  "love"	  the	  open-­‐source	  
concept,	  by	  which	  software	  code	  is	  made	  public	  to	  
encourage	  improvement	  and	  development	  by	  outside	  
programmers.	  Gates himself	  says	  Microsoft will	  gladly	  
disclose	  its	  crown	  jewels-­‐-­‐the	  coveted	  code	  behind	  the	  
Windows	  operating	  system-­‐-­‐to	  select	  customers.
"We	  can	  be	  open	  source.	  We	  love	  the	  concept	  of	  
shared	  source,"	  said	  Bill	  Veghte,	  a	  Microsoft VP.	  
"That's	  a	  super-­‐important	  shift	  for	  us	  in	  terms	  of	  code	  
access.“
Richard	  Stallman,	  founder of	  the	  Free	  Software	  
Foundation,	  countered	  saying…
Microsoft	  Corporation
CEO
Bill	  Gates
Microsoft
Gates
Microsoft
Bill	  Veghte
Microsoft
VP
Richard	  Stallman
founder
Free	  Software	  Foundation
*
*
*
*
From	  William	  Cohen,	  KDD’03	  tutorial
Information	  Integration	  =
association	  +	  clustering
NER	  Example	  (2	  of	  7) 11
<ORG,	  RELATION,	  PERSON>
	  
IE	  is	  a	  general	  technique	  
-­‐	  Segmenting	  data:	  dividing	  the	  data	  into	  
segments	  
-­‐	  Classifying	  the	  data:	  take	  the	  segments	  
and	  put	  them	  into	  categories/attributes	  
(name,	  relation,	  person)	  
	  
	  
Named	  Entity	  Recognition	  (NER)	  
As	  An	  Example
• Input:
Fred	  Flintstone	  was	  named	  CTO	  of	  Time	  Bank	  Inc.	  in	  2031.	  
The	  next	  year	  he	  got	  married	  and	  became	  CEO	  of	  Dinosaur	  
Savings	  &	  Loan.
• Output:
[Fred	  Flintstone]PERSON was	  named	  CTO	  of	  [Time	  Bank	  Inc.]ORG
in	  2031.	  The	  next	  year	  he	  got	  married	  and	  became	  CEO	  of	  
[Dinosaur	  Savings	  &	  Loan]ORG.
NER	  Example	  (3	  of	  7) 12
Omit	  RELATION	  for	  now
	  
Input:	  sentences	  in	  free	  text	  	  
Output:	  annotated	  text	  
	  
How	  to	  Recognize	  A	  PERSON	  Field?
[Fred	  Flintstone]PERSON was	  named	  CTO	  of	  [Time	  
Bank	  Inc.]ORG in	  2031.	  The	  next	  year	  he	  got	  married	  and	  
became	  CEO	  of	  [Dinosaur	  Savings	  &	  Loan]ORG.
NER	  Example	  (4	  of	  7) 13
	  
How	  do	  we	  know	  it	  is	  a	  person	  name?	  
	  
-­‐	  Rely	  on	  common	  sense.	  	  
-­‐	  Using	  the	  “Library”	  in	  your	  brain	  to	  
determine	  whether	  the	  word	  is	  a	  typical	  
name	  phrase.	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
A	  Hard-­‐coded	  Sample	  Code
Function	  RecognizePERSON(String	  s)
n	  =	  s.length;
for	  i =	  1	  to	  n
xi =	  ReadFromInput(s,	  i);
if	  (xi is	  a	  common	  first	  name	  
&&	  xi is	  followed	  by	  a	  capitalized	  token)
output	  yi <-­‐ PERSON
else	  if	  (xi is	  a	  capitalized	  token	  
&&	  xi is	  preceded	  by	  a	  common	  first	  name)
output	  yi <-­‐ PERSON
else	  
output	  yi <-­‐ OTHERS
end
end
NER	  Example	  (5	  of	  7) 14
[Fred	  Flintstone]PERSON was	  
named	  CTO	  of	  [Time	  Bank	  Inc.]ORG in	  
2031.	  The	  next	  year	  he	  got	  married	  
and	  became	  CEO	  of	  [Dinosaur	  
Savings	  &	  Loan]ORG.
	  
Instructor	  shows	  a	  sample	  of	  person	  field	  
recognition	  code.	  The	  code	  has	  several	  
conditions	  for	  checking	  the	  string	  of	  data	  
given.	  
	  
Input	  :String	  s	  
Go	  through	  all	  the	  tokens	  (xi).	  
	  
If	  this	  token	  is	  a	  common	  first	  name	  and	  
followed	  by	  a	  capitalized	  token	  
	  	  	  	  	  Record	  the	  output	  as	  Person	  
Else	  if	  this	  token	  is	  a	  capitalized	  token	  and	  
preceded	  by	  a	  common	  first	  name	  
	  	  	  	  	  	  Record	  the	  output	  as	  Person	  
Else	  	  Record	  the	  output	  as	  Others	  
	  
What	  If	  …
• Input	  1:
Mr.	  Superman	  Flintstone	  was	  named	  CTO	  of	  Time	  Bank	  Inc.	  in	  
2031.	  The	  next	  year	  he	  got	  married	  and	  became	  CEO	  of	  Dinosaur	  
Savings	  &	  Loan.
• Input	  2:
Fred	  Inc.	  is	  a	  financial	  consulting	  firm,	  based	  in	  Chicago,	  Illinois.
• Input	  3:
Mr.	  Fred	  J.	  Flintstone	  was	  named	  CTO	  of	  Time	  Bank	  Inc.	  
in	  2031.	  The	  next	  year	  he	  got	  married	  and	  became	  CEO	  
of	  Dinosaur	  Savings	  &	  Loan.
NER	  Example	  (6	  of	  7) 15
	  
“Rules	  are	  just	  rules.	  There	  will	  be	  a	  lot	  of	  
exceptions!”	  
Some	  issues	  may	  raise:	  
1.	  "Mr.	  Superman	  Flintone"	  should	  be	  
recognized	  as	  Person	  name.	  But	  the	  
above	  rules	  won't	  do	  that.	  
(Fix	  it	  by	  adding	  more	  rules:	  Title:	  Mr.)	  
2.	  Fred	  Inc	  is	  not	  a	  Person	  name,	  but	  it	  
satisfied	  the	  above	  rules	  	  
3.	  Will	  pass	  multiple	  rules	  (	  the	  rules	  in	  
the	  above	  slide	  and	  Title	  rule)	  
	  
Hard-­‐coded	  Method
• Various	  rules	  to	  recognize	  PERSON
– Rule	  R1:	  [	  common_first_name capitalized_token]PERSON
– Rule	  R2:	  Title	  [	  capitalized_token +	  ]PERSON
– …
• There	  are	  multiple	  rules
– Combine	  them	  in	  a	  systematic	  way:	  R1	  *	  2	  +	  R2	  *	  1
• Rules	  are	  not	  always	  correct
– Probabilistic	  output:	  Pr(Fred	  Inc. =	  PERSON)	  =	  0.3
NER	  Example	  (7	  of	  7) 16
	  
Two	  things	  we	  want	  to	  have	  
1.	  Multiple	  rules:	  
Combine	  the	  rules	  in	  a	  systematic	  way.	  
2.	  Rules	  are	  not	  always	  correct:	  
Sometime	  rules	  make	  mistakes.	  	  
Thus	  we	  want	  probabilistic	  output:	  P(Fred	  
Inc	  =	  Person)	  =	  0.3.	  
LEARNING-­‐BASED	  METHODS
Learning-­‐based  Methods  (0  of  6) 17
	  
Basic	  idea	  &	  motivation:	  Human	  learn	  
from	  examples.	  Some	  rules	  get	  you	  good	  
result,	  some	  not.	  	  
Teach	  the	  computer	  the	  significance	  of	  
rules.	  
Reference:	  Machine	  learning	  
(http://en.wikipedia.org/wiki/Machine_le
arning)	  
Overview
Learning-­‐based	  Methods	  (1	  of	  6) 18
Model
M:	  X -­‐>	  Y
Labeled	  training	  data	  
(annotated	  examples	  <x,	  y>)
Test	  data
(un-­‐annotated	  x)
Prediction
(annotated	  <x,	  y>)
Rule	  set
training testing
	  
Apply	  all	  the	  rules,	  and	  check	  the	  results.	  
Some	  rules	  may	  make	  more	  mistakes	  
than	  others.	  Teach	  computers	  which	  rules	  
are	  important,	  which	  are	  not.	  
Labeled	  training	  data:	  annotated	  tokens	  
with	  some	  token	  labels	  
Model:	  combine	  all	  the	  rules,	  and	  rely	  
more	  on	  the	  important	  rules	  	  
Rule	  set,	  such	  as:	  Common	  first	  name,	  
capitalized	  token,	  Title,	  Capitalized	  token	  
Test	  data:	  un-­‐annotated	  x	  
Output:	  annotated	  <x,y>	  
There	  are	  multiple	  rules
• Labeled	  data	  can	  tell	  us	  how	  important	  each	  rule	  is
For	  years,	  [Microsoft	  Corporation]ORG CEO	  [Bill	  Gates]PERSON railed	  
against	  the	  economic	  philosophy	  of	  open-­‐source	  software,	  …
[Gates]PERSON himself	  says	  [Microsoft]ORG will	  gladly	  disclose	  its	  crown	  
jewels-­‐-­‐the	  coveted	  code	  behind	  the	  Windows	  operating	  system-­‐-­‐to	  
select	  customers.
"We	  can	  be	  open	  source.	  We	  love	  the	  concept	  of	  shared	  source,"	  
said	  [Bill	  Veghte]PERSON,	  a	  [Microsoft]ORG VP.	  
[Richard	  Stallman]PERSON,	  founder	  of	  the	  [Free	  Software	  
Foundation]ORG,	  countered	  saying	  …
Learning-­‐based	  Methods	  (2	  of	  6) 19
	  
Supposed	  now	  that	  we	  have	  multiple	  
rules:	  
1.	  Common	  first	  name	  +	  capitalized	  token	  
2.	  Title	  +	  Capitalized	  token	  
Labeled	  data	  can	  be	  served	  as	  training	  
data,	  which	  tell	  us	  how	  important	  each	  
rule	  is.	  
Rules	  are	  not	  always	  correct
• Each	  rule	  contributes	  some	  score
Learning-­‐based	  Methods	  (3	  of	  6) 20
Fred Flintstone	  	  	  was	  named	  CTO	  of	  	  	  Time	  Bank	  Inc.	  	  	  in	  2031.	  The	  next	  
year	  he	  got	  married	  and	  became	  CEO	  of	  	  	  Dinosaur	  Savings	  &	  Loan.
R1 R2 …
Fred
PERSON
	  
Rules	  are	  not	  always	  correct.	  There	  
should	  be	  a	  way	  to	  combine	  the	  rules	  into	  
a	  one	  single	  rule.	  
Each	  rule	  contributes	  some	  score,	  and	  
every	  rule	  tell	  you	  something.	  
For	  token	  x:	  
R1.	  	  PERSON	  	  	  	  	  -­‐-­‐-­‐>	  2	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  true(1)	  
R2.	  PERSON	  	  	  	  	  	  -­‐-­‐-­‐-­‐>1	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  true(1)	  
R3.	  ORG	  	  	  	  	  	  	  	  	  	  	  	  	  -­‐-­‐-­‐-­‐-­‐>	  0.01	  	  	  	  	  	  	  	  false(0)	  
The	  score	  =	  1*2	  +	  1*1	  +	  0.01*0	  =	  3	  
Each	  token	  has	  a	  score	  
Formalized	  Problem
• Let’s	  introduce	  some	  notations
Learning-­‐based	  Methods	  (4	  of	  6) 21
Fred Flintstone	  	  	  was	  named	  CTO	  of	  	  	  Time	  Bank	  Inc.	  	  	  in	  2031.	  The	  next	  
year	  he	  got	  married	  and	  became	  CEO	  of	  	  	  Dinosaur	  Savings	  &	  Loan.
Fred
PERSON PERSON
was
OTHERS OTHERS
Flintstone named
OTHERS
named
……
x1
y1
x2
y2
x3
y3
x4
y4
xn
yn
	  
Xi	  =	  token	  at	  i-­‐th	  position	  of	  the	  string	  
Yi	  =	  label	  at	  i-­‐th	  position	  of	  the	  string	  
Xi	  -­‐-­‐-­‐	  token	  
Yi	  -­‐-­‐-­‐	  label	  (such	  as	  PERSON,	  ORG)	  
f1(xi, yi ) = 10
!
"
#
	  
Rules	  can	  be	  joined	  into	  a	  feature.	  
"Features":	  rules	  applied	  to	  each	  xi	  
Ex:	  R1:	  common	  first	  name	  +	  capitalized	  
token	  
Features	  for	  R1:	  	  
1.	  signal	  =1	  if	  Xi	  is	  a	  common	  1st	  name	  +	  
cap	  +	  Yi=	  Person	  
2.	  signal	  =	  0,	  otherwise	  
For	  each	  token,	  it	  will	  give	  some	  signals	  
	  
	  
Many	  interesting	  ways	  to	  do	  it
Decision	  Tree Support	  Vector	  Machine
And	  so	  on	  …
Images	  from	  Wikipedia
Learning-­‐based	  Methods	  (6	  of	  6) 23
	  
Decision	  Tree:	  Rules	  can	  be	  arranged	  just	  
like	  a	  decision	  tree.	  The	  most	  reliable	  rule	  
should	  be	  on	  the	  very	  top	  of	  the	  tree	  !	  
the	  parent	  of	  the	  nodes.	  
1.	  Always	  choose	  the	  most	  reliable	  rule	  
first	  
2.	  Form	  the	  graph	  
Black	  dots	  :	  PERSON	  
White	  dots	  :	  ORG	  
Find	  approach	  to	  combine	  all	  rules	  and	  
reach	  a	  conclusion	  
CONDITIONAL	  RANDOM	  FIELDS
Conditional  Random  Fields  (0  of  10) 24
	  
	  
Overview
• Conditional	  Random	  Fields	  (CRF)
– Are	  a	  class	  of	  statistical	  modeling	  model
• It	  can	  generate	  probabilistic	  output
• Pr(Fred	  Inc. =	  PERSON)	  =	  0.3
– Take	  an	  exponential	  form	  
• Probability	  is	  in	  the	  exponential	  family
– Used	  for	  structured	  prediction
• Not	  just	  single	  sample,	  but	  also	  context
Conditional	  Random	  Fields	  (1	  of	  10) 25
	  
Conditional	  Random	  Fields:	  given	  a	  set	  of	  
rules,	  what	  is	  the	  probability	  of	  the	  
output?	  
Pr(Fred	  =	  Person)	  
Why	  is	  it	  a	  exponential	  form?	  
Easy	  to	  manipulate.	  Mathematical	  
reasons.	  
	  
	  
	  
	  
	  
s(x, y = y ') = exp λi fi (x, y ')
i=1
3
∑
"
#
$
%
&
'
	  
f1,	  f2,	  f3	  are	  features.	  
Lambda	  =	  weights	  for	  each	  feature	  
Score	  =	  Summation	  of	  the	  
feature*lambda	  
	  
	  Sum	  of	  all	  the	  weights	  
	  Then	  take	  the	  exponential	  of	  the	  sum	  
Example:	  
S(Fred,	  PERSON)	  =	  0.8	  .	  
S(Fred,	  ORG)	  =	  0.1	  
Why	  need	  to	  take	  an	  exponential	  form?	  
Need	  to	  normalized	  (guarantee	  to	  get	  a	  
value	  between	  0	  and	  1).	  
λ>=	  0,	  never	  have	  negative	  values 
s(x, y = y ') = exp λk fk (x, y ')
k=1
K
∑
"
#
$
%
&
'
	  
What	  if	  λ	  is	  unknown?	  
<Xi,	  Yi>	  -­‐-­‐-­‐-­‐>	  right	  λ	  based	  on	  the	  labeled	  
data	  	  
The	  lambda	  is	  the	  model	  upon	  which	  the	  
data	  could	  be	  compared	  and	  evaluated.	  
Optimization:	  
λ*	  	  -­‐-­‐-­‐-­‐>	  model	  	  
(Optimizations	  will	  not	  be	  discussed)	  
Sequential	  Information
• Since	  what	  we	  try	  to	  extract	  is	  a	  sequence
Fred	  Flintstone was named	  CTO	  of	  	  	  Time	  Bank	  Inc.	  	  	  in	  2031.	  The	  
next	  year	  he	  got	  married	  and	  became	  CEO	  of	  	  	  Dinosaur	  Savings	  &	  Loan.
f1 f2 f3
λ1
λ2
λ3
PERSON
f1 f2 f3
λ1
λ2
λ3
OTHERS
λ4
Conditional	  Random	  Fields	  (4	  of	  10) 28
	  
The	  information	  that	  is	  being	  extracted	  is	  
actually	  a	  SEQUENCE.	  The	  tokens	  have	  
dependencies	  between	  each	  other.	  
If	  Flintstone	  is	  a	  Person	  name,	  Fred	  is	  very	  
likely	  to	  be	  Person.	  
How	  about	  "was"?	  
If	  "Dinosaur	  Savings"	  is	  a	  ORG,	  it	  is	  very	  
likely	  "Loan"	  is	  also	  a	  ORG.	  
(followed	  by	  "Dinosaur	  Savings"	  and	  
capitalized)	  
	  
s(x, y = y ') = exp λk fk (x1, y1)
k=1
3
∑
"
#
$
%
&
'
exp λk fk (x2, y2 )
k=1
3
∑
"
#
$
%
&
'
exp λ4 f4 (x1, x2, y1, y2 ){ }
	  
Dependence	  between	  sequential	  tokens	  
s(x, y = y ') = exp λk fk (xi, yi )
k=1
K
∑
"
#
$
%
&
'i=1
n
∏ ⋅
exp λ 'k fk (xi, yi, xi+1, yi+1)
k=1
K '
∑
"
#
$
%
&
'i=1
n−1
∏
	  
 
	  
Even	  More:	  Long-­‐distance	  Information
• Since	  there	  can	  be	  some	  duplicates	  distantly
Fred Flintstone	  	  	  was	  named	  CTO	  of	  	  	  Time	  Bank	  Inc.	  	  	  in	  2031.	  The	  next	  
year	  	  	  Fred got	  married	  and	  became	  CEO	  of	  	  	  Dinosaur	  Savings	  &	  Loan.
Fred
λ
PERSON
λ
PERSON
λ’
Fred
λ
PERSON
got
λ
OTHERS
λ’
Loan
λ
ORG
λ’
Flintstone
λ’’
Conditional	  Random	  Fields	  (7	  of	  10) 31
	  
Long-­‐distance:	  If	  there	  are	  two	  or	  more	  
occurrences	  of	  a	  tag,	  there	  should	  be	  
more	  features	  included.	  
	  
Example:	  
Two	  Fred	  in	  the	  same	  string.	  They	  may	  
refer	  to	  the	  same	  person	  
P(y = PERSON | x = Flintstone)∝ exp λk* fk (Flintstone,PERSON )
k=1
K
∑
#
$
%
&
'
(
...
P(y =OTHERS | x = Flintstone)∝ exp λk* fk (Flintstone,OTHERS)
k=1
K
∑
#
$
%
&
'
(
#
$
)
)
)
%
)
)
)
	  
After	  the	  comparison	  of	  data,	  get	  the	  
maximum	  for	  the	  inference.	  
P(y = PERSON | x = Flintstone,x, y)∝ exp λk* fk (Flintstone,PERSON,x, y)
k=1
K
∑
#
$
%
&
'
(
...
P(y =OTHERS | x = Flintstone,x, y)∝ exp λk* fk (Flintstone,OTHERS,x, y)
k=1
K
∑
#
$
%
&
'
(
#
$
)
)
)
%
)
)
)
	  
Look	  for	  what	  is	  the	  label	  for	  Fred,	  and	  
was	  
The	  ith	  spot	  -­‐-­‐>	  Flinstone	  
Y1	  -­‐	  Yi-­‐1	  -­‐-­‐-­‐>	  forward	  
Yi+1	  -­‐	  Yn	  -­‐-­‐-­‐>	  backward	  
Summary
• Different	  scenarios	  to	  populate	  the	  DB
• IE	  from	  the	  free	  text
• Hard-­‐coded	  method
• Learning-­‐based	  method
– Logistic	  regression
– Conditional	  Random	  Fields
Conditional	  Random	  Fields	  (10	  of	  10) 34
	  
Summary:	  	  
-­‐	  The	  different	  scenarios	  to	  populate	  the	  
DB	  (manual	  vs.	  automated	  =	  web	  
crawling)	  
-­‐	  Hard-­‐coded	  method	  (features	  should	  
created)	  
-­‐	  Learning	  based	  methods:	  If	  there	  are	  
multiple	  rules:	  
Teach	  the	  computer	  the	  significance	  of	  
each	  rule.	  logistic	  regression	  (	  on	  each	  
token)	  
Conditional	  Random	  Fields:	  a	  class	  
of	  statistical	  modelling	  method	  often	  
applied	  in	  pattern	  
recognition	  and	  machine	  learning,	  where	  
they	  are	  used	  for	  structured	  
prediction.	  (From	  Wiki)	  
	  
